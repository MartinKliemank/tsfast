{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp learner\n",
    "# default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from seqdata.core import *\n",
    "from seqdata.model import *\n",
    "from fastai2.basics import *\n",
    "from fastai2.callback.progress import *\n",
    "from fastai2.callback.tracker import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner\n",
    "> Pytorch Modules for Training Models for sequential data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = DataBlock(blocks=(SequenceBlock.from_hdf(['current','voltage'],TensorSequencesInput,clm_shift=[-1,-1]),\n",
    "                        SequenceBlock.from_hdf(['voltage'],TensorSequencesOutput,clm_shift=[1])),\n",
    "                 get_items=CreateDict([DfHDFCreateWindows(win_sz=1000+1,stp_sz=1000,clm='current')]),\n",
    "                 splitter=ApplyToDict(ParentSplitter()))\n",
    "db = seq.dataloaders(get_hdf_files('test_data/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13.357432</td>\n",
       "      <td>12.578009</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SimpleRNN(2,1)\n",
    "lrn = Learner(db,model,loss_func=nn.MSELoss()).fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SkipFirstNCallback(Callback):\n",
    "    \"`Callback` skips first n samples from prediction and target, optionally `with_loss`\"\n",
    "    def __init__(self, n_skip = 0):\n",
    "        self.n_skip = n_skip\n",
    "\n",
    "    def after_pred(self):\n",
    "        self.learn.pred = self.pred[:,self.n_skip:]\n",
    "#         import pdb; pdb.set_trace()\n",
    "        if isinstance(self.yb, tuple):\n",
    "            self.learn.yb = tuple([y[:,self.n_skip:] for y in self.yb])\n",
    "        else:\n",
    "            self.learn.yb = self.yb[:,self.n_skip:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class VarySeqLen(Callback):\n",
    "    \"`Callback` varies sequence length of every mini batch\"\n",
    "    def __init__(self, min_len = 50):\n",
    "        self.min_len = min_len\n",
    "\n",
    "    def begin_batch(self):\n",
    "#         import pdb; pdb.set_trace()\n",
    "        lx = self.xb[0].shape[1]\n",
    "        ly = self.yb[0].shape[1]\n",
    "        lim = random.randint(self.min_len,ly)\n",
    "#         import pdb; pdb.set_trace()\n",
    "        if ly < lx:\n",
    "            self.learn.xb = tuple([x[:,:-(ly-lim)] for x in self.xb])\n",
    "        else:\n",
    "            self.learn.xb = tuple([x[:,:lim] for x in self.xb])\n",
    "            \n",
    "        self.learn.yb = tuple([y[:,:lim] for y in self.yb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11.526955</td>\n",
       "      <td>10.406643</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),cbs=VarySeqLen(10)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.callback.hook import *\n",
    "@delegates()\n",
    "class TimeSeriesRegularizer(HookCallback):\n",
    "    \"Callback that adds AR and TAR to the loss, calculated by output of provided layer\"\n",
    "    run_before=TrainEvalCallback\n",
    "    def __init__(self,alpha=0.0, beta=0.0,dim = None,detach=False, **kwargs):\n",
    "        super().__init__(detach=detach,**kwargs)\n",
    "        store_attr(self,'alpha,beta,dim')\n",
    "        \n",
    "    def hook(self, m, i, o): \n",
    "#         import pdb; pdb.set_trace()\n",
    "        if type(o) is torch.Tensor:\n",
    "            self.out = o\n",
    "        else:\n",
    "            self.out = o[0]\n",
    "        \n",
    "        #find time axis if not already provided\n",
    "        if self.dim is None:\n",
    "            self.dim = np.argmax([0,self.out.shape[1],self.out.shape[2]])\n",
    "    \n",
    "    def after_loss(self):\n",
    "        if not self.training: return\n",
    "        \n",
    "        h = self.out.float()\n",
    "        \n",
    "        if self.alpha != 0.:  \n",
    "            l_a = float(self.alpha) * h.pow(2).mean()\n",
    "            self.learn.loss = self.learn.loss+l_a \n",
    "            \n",
    "        if self.beta != 0. and h.shape[self.dim]>1:\n",
    "            h_diff = (h[:,1:] - h[:,:-1]) if self.dim == 1 else (h[:,:,1:] - h[:,:,:-1])\n",
    "            l_b = float(self.beta) * h_diff.pow(2).mean()\n",
    "            self.learn.loss = self.learn.loss+l_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ARInitCB(Callback):\n",
    "    '''Adds the target variable to the input tuple for autoregression'''\n",
    "    def begin_batch(self):\n",
    "#         import pdb; pdb.set_trace()\n",
    "        self.learn.xb = tuple([*self.xb,*self.yb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.325893</td>\n",
       "      <td>1.634891</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss()).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from matplotlib.lines import Line2D\n",
    "def plot_grad_flow(named_parameters):\n",
    "    '''Plots the gradients flowing through different layers in the net during training.\n",
    "    Can be used for checking for possible gradient vanishing / exploding problems.\n",
    "    *modified version of https://discuss.pytorch.org/t/check-gradient-flow-in-network/15063/8*\n",
    "    \n",
    "    Call multiple time for transparent overlays, representing the mean gradients\n",
    "    '''\n",
    "    ave_grads = []\n",
    "    max_grads= []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "#             pdb.set_trace()\n",
    "            ave_grads.append(0 if p.grad is None else p.grad.abs().mean())\n",
    "            max_grads.append(0 if p.grad is None else p.grad.abs().max())\n",
    "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
    "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(left=0, right=len(ave_grads))\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"Gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)\n",
    "    plt.yscale('log')\n",
    "    plt.tight_layout()\n",
    "    plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n",
    "                Line2D([0], [0], color=\"b\", lw=4),\n",
    "                Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CB_PlotGradient(Callback):\n",
    "    '''Plot the Gradient Distribution for every trainable parameter'''\n",
    "    def begin_fit(self,n_draws=20):\n",
    "        '''Create a new figure to plot in'''\n",
    "        self.n_draws =n_draws\n",
    "        plt.figure()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "    def after_backward(self):\n",
    "        '''plot the gradient for every layer of the current minibatch'''\n",
    "        # plotting n_draws times at the whole training\n",
    "        if self.iter % (max(self.n_epoch*self.n_iter//self.n_draws,1)) == 0:\n",
    "#         if self.iter == self.n_iter-1:\n",
    "            plot_grad_flow(self.learn.model.named_parameters())\n",
    "#             print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.072032</td>\n",
       "      <td>0.055206</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd3wVZfbH8c83kSJdAUGaIAqKqAhIV5G1rqI/FQuKvXdFl1XXXbHXdUV3LSirqNjFrruIggjYaCqgiEKorigqBoQEyPn9MZOQQCAJuffOzdzzfr3yyp1y554MJGeeZ545j8wM55xzLt1kRR2Ac845VxpPUM4559KSJyjnnHNpyROUc865tOQJyjnnXFryBOWccy4teYJyLgKSciQdFL6+TtJjKfpcSXpc0i+SPpXUV9LiVHy2cxXlCcq5jUg6SdInklZJWha+vkiSkvF5ZnabmZ1T2eNIai3JJG2zhd36AAcDLcysW2U/07lk8gTlXDGSrgKGAXcDTYEmwAVAb6D6Zt6TnbIAK28nIMfMVkUdiHNl8QTlXEhSfeAm4CIze8nMci0w3cxOMbO8cL8nJD0k6W1Jq4ADJR0habqk3yQtkjR0o2OfKmmBpOWS/rLRtqGSni623EPSZEm/SvpcUt9i28ZLulnSJEm5ksZIahRunhB+/1XSSkk9N/qcs4HHgJ7h9htLOQe7h5/xq6RZko4K17cJ12WFy49KWlbsfU9JuqJCJ9y5MniCcm6DnkAN4LVy7HsycCtQF5gIrAJOAxoARwAXSvo/AEkdgIeAU4FmQEOgRWkHldQceAu4BdgeuBp4WVLjjT77TGAHglbd1eH6/cPvDcysjpl9VPzYZjaCoDX4Ubj9ho0+uxrwBjAmPPalwChJ7c1sPvAbsE+xz1opafdw+QDggy2dMOcqyhOUcxs0An4ys3WFK4q1ZFZL2r/Yvq+Z2SQzKzCzNWY23sy+DJe/AJ4l+KMNMAB408wmhK2wvwIFm4lhEPC2mb0dHutdYArwx2L7PG5m35jZauAFoFNCfnroAdQB7jCzfDN7H3gTGBhu/wA4QFLTcPmlcLkNUA/4PEFxOAfAlm6mOpdplgONJG1TmKTMrBdAONKt+AXdouJvlNQduAPoSNCqqQG8GG5uVnx/M1slaflmYtgJOF5S/2LrqgHjii3/r9jr3wmSSiI0AxaZWfHkuQBoHr7+ADgKWEzQnTieoFW4Bvhwo/c5V2negnJug4+APODocuy78TQAzwCvAy3NrD7wMFA46u97oGXhjpJqEXTzlWYR8JSZNSj2VdvM7tiKmCpqKdCy8D5TqBWwJHz9AbAf0Dd8PZFg8Ih377mk8ATlXMjMfgVuBB6UNEBSXUlZkjoBtct4e13gZzNbI6kbwX2iQi8BR0rqI6k6wUCMzf3uPQ30l3SopGxJNcNnlUq9Z7WRHwm6Dncux76l+YSgRTZEUrVwcEZ/4DkAM5sLrCbohvzAzH4DfgCOwxOUSwJPUM4VY2Z3AYOBIQR/fH8AHgH+DEzewlsvAm6SlAv8jeDeUOExZwEXE7Syvgd+IegmK+3zFxG04K4jSDiLgD9Rjt9VM/udYODGpPC+WY+y3rPR+/MJEtLhwE/Ag8BpZvZ1sd0+AJaHcRYuC5hWkc9yrjzkExY655xLR96Ccs45l5Y8QTnnnEtLnqCcc86lJU9Qzjnn0lIsH9Rt0KCB7bLLLlGHkRFWrVpF7dpljcB2ieDnOnX8XKfW1KlTfzKzxhuvj2WCatKkCVOmTIk6jIwwfvx4+vbtG3UYGcHPder4uU4tSQtKW+9dfM4559KSJyjnnHNpKZZdfM65qmVpXl7UIZSw1iztYmpWo0bUIaScJyjnXOTG//JLhfbPXr+e5rm51Fi3rqgibyJt36ABS+fOTcKRt96K7Ko0cXPpatasSYsWLahWrVq59vcE5Zyrcprn5tK8QQPqbr89UuJTVNbq1RRsu23Cj1sZDcv5Rz1dmRnLly9n8eLFtGnTplzv8XtQzrkqp8a6dUlLTi45JNGwYUPWrFlT7vd4C8o5F7n5P6wre6didsZYG0wpmZR4ahjkr02zQtpVuwEFUOELCk9QzrnIfbNgfYX23785rMlPXgKphiX1+FulVtQBpJ4nKOdc5H7/tWJ3G2xHKFiXxO69bFGwPn7dh2eccQZHHnkkAwYM4JxzzmHw4MF06NChwscZP3481atXp1evXkmIcgNPUM45V4WtW7eObbap+J/yxx57bKs/c/z48dSpU8cTlHMu/lb/UsEWVAEUrId2X21pkuPK+2b3zf8BXrwwh7NP7k+nzt2ZPuUj9uzUlWNPOo0H7r6Z5T8t455/jQTg1r9eRV7eGmrW3Jbb7xvOzru05/FHhvHNV7O4/b7hzPlqJoMvOJWX3pnEtrVK9uONH/sOtw8dQq1atel3QB/mzZvHm2++ydChQ/nuu++YN28erVq14vbbb+fUU09l1apVAPzzn/+kV69emBmXXnop7777Li1btqR69epFx+7bty/33HMPXbt2ZcyYMdxwww3k5eXRtm1bHn/8cerUqUPr1q05/fTTeeONN1i7di0vvvgiNWvW5OGHHyY7O5unn36aBx54gP322y8JZ99H8Tnn3FZbOP87zrrwCv4z8UvmfTuHN0c/z7Ovj+PPN9zBw/ffSdtd2/PMa+/z2thPuWzI37j39r8BcPq5l7Ig5zvGvP0a115+Ljfd/a9NklPemjX8bcglPDbqdV4Z8zE//vhjie2zZ89m7NixPPvss+ywww68++67TJs2jeeff57LLrsMgFdeeYU5c+Ywe/ZsnnzySSZP3jSh//TTT9xyyy2MHTuWadOm0bVrV+69996i7Y0aNWLatGlceOGF3HPPPbRu3ZoLLriAK6+8khkzZiQtOYG3oJxzaWDNyord7zETBQVJCqaYLX1GgUGLVq3ZtX1HAHZp14EefQ7ETOzaviNLFi5gxa8rGHLp2SyY/y1IrFu7NjxmFrf/41GO/kNXTjj1HPbp2muTz/r2mzm0aNWG5i3bUFAAAwcOZPjw4UXbjzrqKLYNn9Vau3Ytl1xyCTNmzCA7O5tvvvkGgAkTJjBw4ECys7Np1qwZ/fr12+Tn+Pjjj5k9eza9e/cGID8/n549exZtP/bYYwHo0qULo0ePrugprBRPUM45t5WqV99QfkhZWVQLl5WVxfr16xh2941063UA//z3iyxelMNpxx1StH/O/G+pVbsOy/73fdG6swcewfIfl9Fx7y6ccuaFW/zs4tOB/OMf/6BJkyZ8/vnnFBQUULNmzXL/DGbGwQcfzLPPPlvq9hphiaXs7GzWravY4wCV5QnKOVdlfd0+OTfpt6+xhp/zyv9HfnNW/raCJjs2B+CV558qWp/72wpuvX4wT40ey81/uYL/vDmaw448lhHPvlW0z5rVq1m8YD6LF+XQomVrnn/++c1+zooVK2jRogVZWVmMHDmS9euDYfv7778/jzzyCKeffjrLli1j3LhxnHzyySXe26NHDy6++GK+/fZbdtllF1atWsWSJUto167dZj+vbt26/Pbbb1t1TiqiXAlK0vFm9mJZ61xypVvxSki/opqZWFDTpa+zL7qKa644m4fvu50DDjq8aP3tN/yJk8+4gDZt23Hr3x/h9OMPYd8efWjYaIeifWpuuy1/u30Y557cn21r1Wa/Xt02+zkXXXQRxx13HE8++SSHHXZYUevqmGOO4f3336dDhw60atWqRNddocaNG/PEE08wcOBA8sLf5VtuuWWLCap///4MGDCA1157LamDJGRW9sNokqaZWeey1qWL9u3b25w5c6IOI+HSKREUmjV5MnskeahpRcQ5QcV5Er397l5Yof1v2m8FO7be/B/QympYfQ3L8yvfgqqsVatWUrt2HcyMB24ezK677sqVV14ZdViV8tVXX7H77ruXWCdpqpl13XjfLbagJB0O/BFoLun+YpvqAantjHTOuQzz4tP/5rUXn2Ztfj7d9+3M+eefH3VIKVVWF99SYApwFDC12PpcoGqn8Sroy5Urow5hE3kFBWkVV5xbUC7znHH+ZZxxfjBkfLemmfd/e4sJysw+Bz6X9IyZrU1RTM4551y5R/F1kzQU2Cl8jwAzs52TFVhlFADTcnOjDqNI57p1ow7BubSWt6Jik/GZgSWxVp6Zknp8Vz7lTVAjCLr0pgIVKzscAQN+zM+POoyEW742/RqxNc1YmYZxOeeqvvImqBVm9k5SI0kks7T8Y+6cK10+FS8LkexCEikoVOHKUN4ENU7S3cBooGiss5lNS0pUrlS/pGHS3cEsLeNyzlVMnTp1WLlyJUuXLuWyyy7jpZde2qrj3HfffZx33nnUqlX5CazKm6C6h9+Lj1M3YNPCTs4559LC+vXryc6u2P29Zs2abXVygiBBDRo0KHUJyswOrPQnpVABMH/16qjDSLhfU1wHqzwamqVlXC4zdGxRveydtkpw3JmLN38ve8miHC4Y1J+9OndnxpSP6Lh3V/7vxNP4199v5ueflnHnAyNp274Dt/31Sr79ehbr1q3losHX0+/Qo1iyKIdrLz+L1b8H02Ncd8t97NO1J59O/oAH772F7bZvyLdzZtFhz87c8cATm0yVXlBQwCWXXML7779Py5YtqVatGmeddRYDBgygdevWnHjiibz77rsMGTKE3Nxchg8fTn5+PrvssgtPPfUUtWrVYv78+Zx88smsXLmSo48+uujYOTk5HHnkkcycOZP169dzzTXXMH78ePLy8rj44os5//zzGT9+PEOHDqVRo0bMnDmTLl26FE29sXTpUg488EAaNWrEuHHjKvWvUN5SR02A24BmZna4pA5ATzMbUalPd845YO2ailYzD+aESrYtfYYVwMKc77jnoWe56e7hnHRkL9565XmefHkc4959g+EP3EnbXXenW8++3Hz3cH5b8SsnH9Wb7r3/wHbb78Dwp9+mRs2aLJg/lyGXnMbzb30EBl/PmsErY6ezQ5NmnHpsX6Z9MpnO3XqX+OzRo0eTk5PD7NmzWbZsGbvvvjtnnXVW0faGDRsybVpwB2b58uWce+65AFx//fWMGDGCSy+9lMsvv5wLL7yQ0047jX/961+l/owjRoygfv36fPbZZ+Tl5dG7d28OOSQoeDt9+nRmzZpFs2bN6N27N5MmTeKyyy7j3nvvZdy4cTRq1Kgypx4ofxffE8DjwF/C5W+A5wlG97kU+S0NWyrrzdIyLudSoXnL1rTbbcN0G917H4gUTLexdPECfvh+CePffZORw/8BQF5eHv9bspDGTZpx21+v4OvZn5Odnc2CeXOLjtlx76403bEFALt12IslixdskqAmTpzI8ccfT1ZWFk2bNuXAA0t2cp144olFr2fOnMn111/Pr7/+ysqVKzn00EMBmDRpEi+//DIAp556Kn/+8583+fnGjBnDF198UdTlt2LFCubOnUv16tXp1q0bLVoEcXbq1ImcnBz69Omz9SezFOVNUI3M7AVJ1wKY2TpJaT/c3Dnnkmnj6TYKl7Oysli/bh1ZWdnc+8hztGnbvsT7Hrz3Zho23oGX/zuFgoICuu5ar9RjZmVns379Or6Y/imD+l8CwE033VRmXMWn4jjjjDN49dVX2XvvvXniiScYP378hpi15ZarmfHAAw8UJbVC48ePL5qGA5I3FUd5E9QqSQ0JBkYgqQewIuHRlELS/wFHENT/G2FmY1Lxuc659PflwuQ877hDrTUs+73yxWJ7H3AwzzzxINfddB+S+GrmDHbv2Inc3BU03bE5WVlZvPbSU0XTY2zOXvt0Y8aMGUXLeXl5jBw5ktNPP50ff/yR8ePHbzKNRqHc3Fx23HFH1q5dy6hRo2jePJj+o3fv3jz33HMMGjSIUaNGlfreQw89lIceeoh+/fpRrVo1vvnmm6L3b07dunXJzc1NaRffYOB1oK2kSUBjYEBZb5L0b+BIYJmZdSy2/jBgGJANPGZmd2zuGGb2KvCqpO2Ae4CMTVC5ZfwnjsJ6s7SMy7l0cP7l13Hn0Ks49pAuWEEBzVu25l9PvMpJp53PleefxOsvj6L3AYewba3aZR+smOOOO4733nuPDh060LJlSzp37kz9+vVL3ffmm2+me/fuNG7cmO7du5MbVtkZNmwYJ598MnfeeWeJQRLFnXPOOeTk5NC5c2fMjMaNG/Pqq69uMbbzzjuPww47jGbNmlV6kES5ptsAkLQN0J6gzNGc8tTmk7Q/sBJ4sjBBScomuId1MLAY+AwYSJCsbt/oEGeZ2bLwfX8HRpXn2aud27Wzs//733L9XKnwlzZtEnKci77+OiHHSaQeOTl83Lp11GEUeXC33aIOIWniPN3GHlcvrtD+9x/7C01ati97x62UqBZUInVsWXLE4sqVK6lTpw7Lly+nW7duTJo0iaZNm0YUXfklcrqNfmb2vqRjN9rUThJmtsUJ6s1sgqTWG63uBnxrZvPCz3gOONrMbidobW0cg4A7gHe2lJwknQecB9CocWPazp27uV1TbvyCBQk5To81axJynESqnZ9Pj5ycqMMoMv5//4s6hKRZuXJlifsHcXJRp4o97F23WkN2qJW834dtsgqSevytkZtbcj64P/7xj6xYsYL8/Hz+9Kc/Ubt27aLWUTpbs2ZNuf8fl9XFdwDwPtC/lG1GUFmiopoDi4otL2bDg8CluRQ4CKgvaRcze7i0ncxsODAcghbUd7vuuhWhJcdJ3oJKmdO8BVUlXVzRFtTOvyS1hZOWLaiGJVtQH374YUSRVE7NmjXZZ599yrVvWdNt3BB+PzMBcW0VM7sfuL/MHZ1zzsVKWV18g7e03czu3YrPXAK0LLbcIlznnHPOFSmri69wIqP2wL4EI/kg6PL7dCs/8zNgV0ltCBLTSUDp4yOdc85lrLK6+G4EkDQB6GxmueHyUOCtsg4u6VmgL9BI0mLgBjMbIekS4L8EI/f+bWazKvNDZIofcypW9DEV1uUrveKK7y0o5zJOeZ+DagIUfyIuP1y3RWY2cDPr3wbeLudnu9Dq1ek3w2eB0jMu59ymWrduzZQpU2jUqBG9evVi8uTJW3WcJ554gkMOOYRmzZolOMKSssq535PAp5KGhq2nT4CRSYvKOediqqyqERW1tSWGtjY5QZCgli5dutXvL6/yTrdxq6T/AIWVAM80s+nJC6tyzGDJz2lU3SAxo8xZk5t+LZWC2rBmVfrF5TLDnq1qlL1TJXy5MG+z2154ajgvjHoUgJW5K2jWojXnXPwn/nXvzazNz6NFq5255e+PUqt2HQ7t1Y5DjxzAxxPf48wLrqJN2/bcfN0lrF79Oy132pmb7h5O/QbbbfIZDw+7jbdeeYbttm9M+11a0aVLF66++mr69u1Lp06dmDhxIgMHDqRdu3bccsst5Ofn07BhQ0aNGkWTJk1Yvnw5AwcOZMmSJfTs2ZPihRkKJygEuPvuu3nhhRfIy8vjmGOO4cYbbyQnJ4fDDz+cPn36MHnyZJo3b85rr73GW2+9xZQpUzjllFPYdttt+eijj9h2220TfOYD5W1BYWZTgWeBV4DlklolJaIEWZWrtPlyzsXPCaeex0v/+Yxn35hMk6YtOOaE03nk/jt49Jl3eOHtT9hjry6MfHRY0f4NttueF97+hMOPOoHrrjyLK669ldFjprLrbh15+L5bNjn+zM+nMPadV3jpP1N46MnXmTJlSont+fn5TJkyhauuuoo+ffrw8ccfM336dE466STuuusuAG688Ub69OnDrFmzOOaYY1i4cOEmnzNmzBjmzp3Lp59+yowZM5g6dSoTJkwAYO7cuVx88cXMmjWLBg0a8PLLLzNgwAC6du3KqFGjmDFjRtKSE5R/PqijgL8DzYBlQCvga2CPpEVWCWawfEm5c2+VkZeGczBarfSMy7lUuXPoYLr16ku9+g2YN/crTju2LwBr8/PZu0uPov0O6388ALm/rSD3txXs22N/AI4+bhBXXbTpQObpn03mwIP7U6NmTWpQk/79S9ZLKD6lxuLFiznxxBP5/vvvyc/Pp01YHGDChAmMHh3UUzjiiCPYbrtNW2ljxoxhzJgxRQ/Prly5krlz59KqVSvatGlDp06dAOjSpQs5Ka4aU95BEjcDPYCxZraPpAOBQckLyznn0t+rLz7J0iULue7mYUx472167vcH7vrnU6XuW1ZB2P8tXcQlZwVV5U445dwyP7v4lBqXXnopgwcP5qijjiqa7ba8zIxrr72W888/v8T6nJycTabUWJ3imcrLm6DWmtlySVmSssxsnKT7khqZc86VYUv3iCqjPKWOZn0xjZGP/IMnXnqfrKws9urcnVv/egULc76lVetd+P33VSz73xJa79yuxPvq1qtPvfoNmPrJRLp078Mbo5+hS/f9aNqsJS/957Oi/WZ+PoWbrr2Ycy4ewvr163jzzTc577zzSo1lxYoVRdNgjBy5Yfza/vvvzzPPPMP111/PO++8wy+//LLJew899FD++te/csopp1CnTh2WLFlCtWrVtvizF06pkWzlTVC/SqoDTABGSVoGrEpeWM45l96eHfkQK379hbNPCqZA32OvLtzy90cZcslp5OcHifPSq4dukqAAbr13RNEgiRat2nDzPY9usk/HvbvS96AjOe7QLjRs1IQ999xzs1NqDB06lOOPP57tttuOfv36MX/+fABuuOEGBg4cyB577EGvXr1o1WrToQOHHHIIX331FT179gSCwRNPP/002dmbf77xjDPO4IILLkj6IIlyTbchqTawmmBQxSlAfYKpL5YnJapK2qltO2tyQfpMG/Xpn1on5Dj7PfJdQo6TSIMafsvTy3eJOowiH57fNuoQkibOxWJ9uo3S/b5qJbVq12H16t+58OSDGD58OJ07d446rEpJ2HQb4RuzgTfN7ECgAH/+yTnnUmLoNRcxb+5X5OWt4byzz6jyyamiykxQZrZeUoGk+maWkmnenXPOwV0PPFn0euMJCzNBee9BrQS+lPQuxe49mdllSYnKlSp3Ufr9B11fNyst43LxVmDB6LNgPlNXVZR3BvdC5U1Qo9kwOWHhJ/j/DOdcJBb/mk3Dhr9QrdZ2nqSqCDNj+fLl1KxZ/nt7Zc0HdTTQwsz+FS5/CjQmSFJ/rkSsbiusXZN+v4hWkJ5xuXh7ZHIdzudnWjT4kawk/Pf7vdpactdueah1qmWvLG97In3VrFmTFi1alHv/sn7iIQTzNRWqDnQB6gCPAy9WNEDnnKus3Lws7hlXL2nHv6jTVzw4Y/eyd0yhWfeU/w97XJSVoKqb2aJiyxPN7Gfg53DouXPOOZcUZRWsK1G4ycwuKbbYOPHhOOecc4GyEtQnkjYpCiXpfLZ+ynfnnHOuTGV18V0JvCrpZGBauK4LUAP4v2QG5pxzLrNtMUGZ2TKgl6R+bJha4y0zez/pkTnnnMto5Z1R933Ak5JzzrmUqfoD60tjkL9i85V4nXPOpb/4TTvrnHMuFjxBOeecS0ueoJxzzqUlT1DOOefSkico55xzackTlHPOubTkCco551xaiuVzUIbPUeScc1Wdt6Ccc86lJU9Qzjnn0pLMLOoYEk5SLjAn6jgyRCPgp6iDyBB+rlPHz3Vq7WRmm8wxGMt7UMAcM+sadRCZQNIUP9ep4ec6dfxcpwfv4nPOOZeWPEE555xLS3FNUMOjDiCD+LlOHT/XqePnOg3EcpCEc865qi+uLSjnnHNVnCco55xzackTlHPOubTkCco551xaik2CknSzpIMl1Y46lkwgaXtJ20cdR9xJeq8861zlSbqzPOtc6sQmQQHzgIHAFEmfSvq7pKOjDipOJLWS9JykH4FPgE8lLQvXtY42uniRVDO8AGgkabvCC4LwPDePNrrYOriUdYenPApXJHbDzCU1BU4Arga2M7O6EYcUG5I+Au4DXjKz9eG6bOB44Aoz6xFlfHEi6XLgCqAZsAQonD/mN+BRM/tnVLHFjaQLgYuAnYHvim2qC0wys0GRBObik6AkPQZ0AH4APgQmAtPMbF2kgcWIpLlmtmtFt7mtJ+lSM3sg6jjiTFJ9YDvgduCaYptyzeznaKJyEK8E9QrB1eZs4ANggpnNizaqeJH0HPAzMBJYFK5uCZwONDKzE6KKLc4k9QJaU6y4s5k9GVlAMRb2CDSh5LleGF1EmS02CaqQpN2BQ4ErgWwzaxFxSLEhqTpwNnA0G+6DLAFeB0aYWV5UscWVpKeAtsAMYH242szssuiiiidJlwBDCXphCsLVZmZ7RRZUhotNgpJ0JLAfsD/QAPgY+NDM/h1pYM5VgqSvgA4Wl1/UNCbpW6C7mS2POhYXiNN8UIcR3HsaZmZLow4mjiQ9AGz2D6Vf1SfFTKAp8H3UgWSARcCKqINwG8QmQZnZJVHHkAGmRB1AppD0BsHFQF1gtqRPgaIuVDM7KqrY4kbS4PDlPGC8pLcoea7vjSQwF58EJakH8ACwO1AdyAZWmVm9SAOLETMbWZ79JD1gZpcmO56YuyfqADJI4aMoC8Ov6uGXi1ic7kFNAU4CXgS6AqcB7czs2kgDy0CSpplZ56jjcM5VbbFpQQGY2beSssOHSB+XNB3wBOWqLEm5bHrfbwVBd+tV/ihF4hTrVi2u8Fw/YmZrUh9VZotTgvo9HAY9Q9JdBDeV41TKyWWm+4DFwDME1SROIhh2Pg34N9A3ssjiZx7QGHg2XD4RyAXaAY8Cp0YUV8aKUxffTgTPL1QneAaqPvCgmX0baWAZSNJ0M9sn6jjiQNLnZrb3RutmmFmn0ra5rSfpMzPbt7R1kmaZ2R5RxZapYtHCCJ/+vs3M1pjZb2Z2o5kN9uQUmWFRBxAjv0s6QVJW+HUCUNjVFI+ry/RRR1KrwoXwdZ1wMT+akDJbLLr4zGy9pJ0kVTcz/4+UZJLaAX8CdqJkSZh+4fcnookslk4hSPgPEiSkj4FBkrYF/NGKxLoKmCjpO4Lu1DbAReEUPuUaweoSK05dfE8SDDF/HVhVuN6fYUg8SZ8DDwNT2VB+BzObGllQziWApBrAbuHiHB8YEa1YtKBC34VfWWx4rsElxzozeyjqIOJM0hAzu2tz1Tu8akfiSOpnZu9LOnajTW0lYWajIwnMxSdBmdmNW9ruD49WXrEZdPkptTYAABV9SURBVN+QdBHwCiWfuPepCRLnq/C7V+9IvgOA94H+pWwzwBNURGLTxVcWf3i08iTNJ/iFVSmbzcx2TnFIGUNSLTP7Peo4nEulWIzic6lhZm3MbOfw+8ZfnpySQFJPSbOBr8PlvSU9GHFYsSSpiaQRkt4JlztIOjvquDJZbLr4XPJtoa8ewPvqk+M+gvnNXgcws88l7R9tSLH1BPA48Jdw+RvgeWBEVAFlukxKUKV1S7mK8b76CJjZIqnEf9/1m9vXVUojM3tB0rUAZrZOkp/rCGVSgvKHRyvJzG4Iv5+5pf0knV7eyueuTIvCKd9NUjXgcjYMoHCJtUpSQ8JRk+EMCT4/VISq/CAJSfUJCsL+H7ADwX+uZcBrwB1m9muE4WUkH5CSOJIaEVxcHUTQCzAGuNxnfU08SV2A+4GOBBNFNgYGmNkXkQaWweKQoP5L0O000sz+F65rCpwO/MHMDokyvkzktfgSR1JNf1g0dSRtA7QnuBiYY2ZrIw4po8UhQc0xs/YV3eaSx1tQiSPpW4IiyB+GXxPNzLudkkDSROADgvM8ycxyIw4p48VhmPkCSUMkNSlcEQ4X/TOwKMK4MpkPSEkQM9sFGAh8CRwBfC5pRrRRxdapwBzgOGCypCmS/hFxTBktDgnqRKAh8IGkXyT9DIwHtgdOiDKwuJLUpox1k1IYTqxJagH0BvYD9gFmEQx9dglmZvOBd4H3gAlALYL6ni4iVb6Lz6VeaV14kqaaWZeoYoorSQXAZwTTybwWdTxxFlYx/4lgcsgPgRlmVhBtVJmtyg8zlzR4S9u9mnniSNoN2AOov9HDuvWAmtFEFXv7AH2AkyVdA8wFPjAzf3g08e4nONcDCc77B5ImmNl30YaVuap8C0rSDVvaXlYRWVd+ko4mGM5/FGFlg1Au8JyZTY4ksJiTVIfgD+d+wCAAM9sp0qBiLDzfZwJXAy3MLDvikDJWlU9Q5SXpWjO7Peo44kBSTzP7KOo4MoGkKUANYDLhSD4zWxBtVPEk6e8EFwJ1CM73RILzPS/SwDJYJiUoH/qcIJIaA+cCrSk5o+5ZUcUUV5Iam9mPUceRCSQNIEhIP0QdiwtU+XtQFeBDnxPnNYKr+bF4XbikKi05SepsZtOiiCfOzOylqGNwJWVSgsqMpmJq1DKzP0cdRAa7kKAF65LMe16iFYfnoMrLW1CJ86akP0YdRKYyM09OKeLJKVqZ1IJ6MeoAqjpJuWyYUfc6SXnA2nDZzKxelPHFTVgI+TCgebhqCfBfL4DsMkVsBkn4jXsXJ5JOA24gqF6+JFzdAjgYuNHMnowqtrgpduG1ySb8witScUpQhcNwp1Lsxr2ZvRxZUDElqbRujxXAAjNbl+p44kjSHKD7xq0lSdsBn5hZu2gicy514tTF5zfuU+dBoDNBAVOAPQnmz6kv6UIzGxNZZPEhSr+qL8DvpyaVpB0oVhnFzBZGGE5Gi1OCelPSH83s7agDyQBLgbPNbBaApA7ATcAQgmnfPUFV3q3ANElj2FCVvxVBF9/NkUUVY5KOAv4ONCOY9HQngtmL94gyrkxW5bv4NrpxXxvwG/dJJmmmmXUsbZ2kGWbWKarY4iTszjuUTQdJ/BJdVPEl6XOgHzDWzPaRdCAwyMzOjji0jFXlW1BmVjfqGDLQLEkPAc+FyycCsyXVILg4cAkQJqLnytzRJcpaM1suKUtSlpmNk3Rf1EFlsiqfoIqT1JygWV58FN+E6CKKrTOAi4ArwuVJBIU11wIHRhRTxpA03MzOizqOGPo1LBQ7ARglaRmwKuKYMlqV7+IrJOlOwit5NoziMzM7KrqonEs8SV3MbGrUccSNpNrAGoLbA6cA9YFRZrY80sAyWJwS1BxgLzPLizqWuJL0gpmdIOlLShlhZmZ7RRBWxpCUBdQxs9+ijsW5VIhTF988oBrBIAmXHJeH34+MNIoMIukZ4AKCXoHPgHqShpnZ3dFGFj/hJJx3AjsQtKJ8oFXEqnwLStIDBFfzzYG9gfcolqTM7LKIQos1STsBu5rZWEnbAtuYWW7UccVN4ahISacQPHt2DTDVW6uJJ+lboL+ZfRV1LC4QhxbUlPD7VErO8uqSRNK5wHnA9kBbghI8DwN/iDKumKomqRrBTMb/NLO1kqr2VWX6+sGTU3qp8gnKzEaWZz9JL5vZccmOJ0NcDHQDPgEws7nh0/cu8R4GcoDPgQlhy9XvQSXHFEnPA69SshdmdHQhZbYqn6AqYOeoA4iRPDPLl4KKO5K2wefbSrhwUMQPZta82LqF+FD+ZKkH/A4cUmydEVRHcRHIpATlf0AT5wNJ1wHbSjqY4JmoNyKOKXbMrEDSEOCFYusM8IK8SWBmZ0Ydgyupyg+SKC+fGTNxwiv7swmuNAX8F3jMMuU/UwpJugP4CXieYg+NmtnPkQUVM5KGmNldxQZcleADraKTSQlqupntE3UccSDpD8BkM1sddSxxJ2l+KavNzLzLOkEkLTezhpKuADapc1je+9wu8WLTxSfpcjMbtoV1PhVH4pwGPCTpZ4I5uCYAE72IaeKZWZuoY8gAP0hqBpwJ9MWnM0kbsWlBldaF562m5Ap/qQcQ1OFrZmaxueBJF5JqAYOBVmZ2nqRdgfZm9mbEocWGpEsJ7qPuzIbZi2HDg7reWo1IlU9QkgYCJwN9CK7mC9UFCszMn81JMEmDgP0IJir8CZgIfGhmH0UaWAyFw56nAqeF05nUIuhe9SlNEkzSQ2Z2YdRxuA3ikKB2AtoAtxM8ZV8oF/jCpyBPPEk/Ad8RPKMzzsxyoo0oviRNMbOuxXsDJH1uZntHHZtzyVblu2TMbAGwAOgZdSyZwswaSdoD2B+4Nex2mmNmp0YcWhzlh6WkDEBSW7zepMsQWVEHkCiSjpU0V9IKSb9JypXkT9wngaR6BNOP7wS0JpiWoCDKmGJsKPAfoKWkUQS1JodEGpFzKVLlu/gKeaHH1JH0BcF9p4nABDNbHHFIsSapIdCD4Kb9x2b2U8QhOZcSVb6Lrxgv9JgiXkk7dSS9DIwA3jEzb6W6jFLlW1DhHC4ABwBN8UKPkZB0npkNjzqOuJF0EMHzOT2AF4HHzWxOtFE5lxpxaEH1L/baCz1Gxx9uTAIzGwuMlVQfGBi+XgQ8CjxtZmsjDdC5JKryLSjn4i68BzUIOBVYCowieO5vTzPrG2FoziVVbBKUpPtLWb0CmGJmr6U6njiT1AS4jaB6xOGSOgA9zWxExKHFjqRXgPbAU8ATZvZ9sW1TzKxrZME5l2RxSlDDgd0I+ukBjgPmAw2BeWZ2RVSxxY2kd4DHgb+Y2d7hfFDTzWzPiEOLHUkHmtm4qONwLgpxSlAfA73NbH24vA1B6aM+wJdm1iHK+OJE0mdmtu9G1Q1mePmd5JDUEegA1CxcZ2ZPRheRc6kRh0EShbYD6hB06wHUBrY3s/WS/Mn7xFoV3hcprG7Qgw3n3SWQpBsIKmx3AN4GDid4/swTlIu9OCWou4AZksYTjCjbH7hNUm1gbJSBxdBg4HWgraRJQGOCquYu8QYAexN0oZ4Z3v97OuKYnEuJ2HTxAUjaEegWLn5mZkujjCfOwi7U9gQXA3N8uHNySPrUzLpJmgocSFAE+Ssz2y3i0JxLuirfgpK0m5l9LalwLqhF4femkpqa2bSoYoubYg9Fb6ydJH8oOjmmSGpA8NzTVGAl4NOauIxQ5VtQkoaHE7mVNtLJzKxfyoOKKUmPb2GzmdlZKQsmA0lqDdQzsy8iDsW5lKjyCcq5OCrWI1Aq7xlwmSA2Ccqnxk4dSX8rbb2Z3ZTqWOJqMz0ChbxnwGWEKn8PqpjHCfroe4XLSwge2vUElXirir2uCRwJeCX5BDKzA8uzn6SDzezdZMfjXBTi1ILyqbEjIqkG8F+vC5d6kqaZ2Ra7A52rqmIzoy4+NXaUagEtog4iQ3kVeRdbceriG0rJqbF7A2dEGVBcSfqS8EIAyCZ4UNfvP0UjHl0gzpUiNl184FNjp4qknYotriOYzXhdVPFkMu/ic3EWmxaUpKeBD4APzezrqOOJI0nbhy9zN9pUL3xQ9+dUx+TIiToA55IlNi0oSQcC+4VfbYHpwAQzGxZpYDEiaT5Bl5KAVsAv4esGwEIzaxNheLEkKRs4AmhNsQtKM7s3qpicS5XYJCgo+mXel6Bm2QXAaq9ZlniSHgVeMbO3w+XDgf8zs/OjjSx+JL0NrAG+BAoK15vZjZEF5VyKxCZBSXqPYIqNjwjmgZpoZsuijSqeJH258eSEpa1zlSfpCzPbK+o4nItCnIaZfwHkAx2BvYCO4bBzl3hLJV0vqXX49RfAK8cnxzuSDok6COeiEJsWVCFJdQmGl18NNDWzGtFGFD/hYIkbCObcApgA3OiDJBJP0jEE8z9lAWsJ7vmZmdWLNDDnUiA2CUrSJQQDJLoQjGz6kGBE3/tRxhVn4cWAmdnKqGOJq3BgytHAlxaXX1bnyik2w8wJasLdC0z1Z3KSS9KeBFOObx8u/wScbmYzIw0snhYBMz05uUwUmxaUSx1Jk4G/mNm4cLkvcJuZ9driG12FSXoC2Bl4h2Klu3yYucsEcRoksQlJXsk8OWoXJicAMxtPMILSJd584D2gOlC32JdzsRenLr7SnBt1ADE1T9JfgafC5UHAvAjjiaXwub66ZnZ11LE4F4VYtaAkbV+sHA9m9n2U8cTYWQQFYkeHX43DdS6BzGw9QdFj5zJSlb8HJakVcBfwB+BXgmG49YD3gWvMLCe66JyrHEkPAc0JJt8smijSzEZHFpRzKRKHLr7ngfuAU8IrzsKukeOB5wiqm7sEktQVuI5N68N5xYPEqwksB4pP8W4ELVfnYi0OLai5ZrZrRbe5rSdpDvAnNq0PtyCyoJxzsROHFtRUSQ8CIwmeGQFoCZxOUNHcJd6PZvZ61EFkAkktgAfYcC/qQ+ByM1scXVTOpUYcWlDVgbMJnrZvHq5eDLwBjDAzn/Y9wST9ARhIMPy5+LM53u2UYJLeBZ6h5IjJU8zs4Oiici41qnyCcqkXTg65GzCLDV18ZmY+ki/BJM0ws05lrXMujuLQxbdZko40M39YN/H2NbP2UQeRIZZLGgQ8Gy4PJBg04Vzsxeo5qFLsG3UAMTVZUoeog8gQZwEnAP8DvgcGAGdGGpFzKeJdfK7CJH0FtCUow5PHhikgfJi5cy5hYpOgJB0P/MfMciVdD3QGbjYzH8mXYJJ2Km29DzNPPEmNCUp2tabkM2d+v8/FXpwS1BdmtpekPsAtwN3A38yse8ShObfVwsrxHwJTgfWF683s5ciCci5F4jRIovCX9whguJm9JemWKAPKJJLeNLMjo44jhmqZ2Z+jDsK5KMRpkMQSSY8AJwJvS6pBvH6+dOeV45PjTUl/jDoI56IQpy6+WsBhBFNjz5W0I7CnmY2JOLRYKqwab2Y/Rx1LnEnKJZhrKw9Yy4YBKfUiDcy5FIhNgoKiIrFNKHkzeWF0EcWLV453zqVSbBKUpEuBG4AfKFndwIc+J4ikjwgqx79USuX4K8zMK8c75xImTgnqW6C7mflT9knilePTg6RpZtY56jicS7Y4jeJbBKyIOoiY88rxacCTk8sUcWpBjQDaA29RssL2vZEFFTNeOd45l0pxSlA3lLbezG5MdSzOJYqkY4E7gR0IBqX4KD6XMWKToFy0vHJ8coT3Vvub2VdRx+JcqsXmHpSkdsDVbFqzrF9UMWWYfQFPUIn3gycnl6li04KS9DnwMJvWLJsaWVDOVZKkYUBT4FV89mKXYWLTggLWmdlDUQeRCbxyfErVA34HDim2zgBPUC724tSCGgosA16h5JWml+JJMK8c75xLhTglqPmlrDYz2znlwcScpOlmto+k2wlqHz5TuC7q2OLG54NymSwWXXySsoBBZjYp6lgyRGHl+IOBO71yfFK9RjAf1FiK3Vt1LhPEqQXlV/Ap4pXjU0fSDDPrFHUczkUhTle970k6TpKiDiTuzOx3giv7VWGF82rA19FGFVs+H5TLWHFqQRXOm7MOWIM/cZ80Xjk+NcKLrcJuPZ8PymWc2CQolzpeOT51JM00s45Rx+FcFOLUxedSxyvHp85USftGHYRzUYh1C8rnzUkOrxyfOpK+BnYBFgCr2NDF592pLvZiMcx8czw5Jc3C8Kt6+OWS59CoA3AuKrFuQTnnnKu6YtOC8nlzUscrxzvnUiE2LSifNyd1vHK8cy4VYtOCwufNSSWvHO+cS7o4taB83pwU8crxzrlUiFOCeryU1eZVnxPPK8c751IhNgnKpUZYOb6nV453ziVbbBKUz5uTOl453jmXCnEaJOHz5qTOe5KOA0ZbXK5wnHNpJ04tKJ83J0W8crxzLhXiVCzW581JETOra2ZZZlbdzOqFy56cnHMJFYsWlM+b45xz8ROLFlR4H2R2eFW/rV/Vp56kaVHH4JyLl1gkqJDPmxMhrxzvnEu0WHTxgc+b45xzcROnBLVTaevNbEGqY4k7rxzvnEuF2CQolzpeOd45lwpxugflUscrxzvnks5bUK7CvHK8cy4V4lTqyKVOPeB34JBi6wzwBOWcSxhvQTnnnEtL3oJyFeaV451zqeAJym0NrxzvnEs67+JzFeaV451zqeDDzN3W8Mrxzrmk8xaUqxCvHO+cSxW/B+UqxMxM0mwz6xh1LM65ePMuPrc1vHK8cy7pvIvPVZhXjnfOpYInKFdhXjneOZcKnqCcc86lJb8H5ZxzLi15gnLOOZeWPEE5l0KSVkYdg3NVhSco52JIkj/j6Ko8T1DORUxSf0mfSJouaaykJpKyJM0NK8cTLn8rqXH49bKkz8Kv3uE+QyU9JWkS8JSkPSR9KmmGpC8k7RrpD+pcBXmCci56E4EeZrYP8BwwxMwKgKeBU8J9DgI+N7MfgWHAP8xsX+A44LFix+oAHGRmA4ELgGFhYd+uwOKU/DTOJYh3AzgXvRbA85J2BKoD88P1/yaY2uQ+4Czg8XD9QUCHoCwiAPUk1Qlfv25mq8PXHwF/kdQCGG1mc5P7YziXWN6Cci56DwD/NLM9gfOBmgBmtgj4QVI/oBvwTrh/FkGLq1P41dzMCgdfrCo8qJk9AxwFrAbeDo/jXJXhCcq56NUHloSvT99o22MEXX0vmllhFfkxwKWFO0gqdW4uSTsD88zsfoKWmJeiclWKJyjnUquWpMXFvgYDQ4EXJU0Fftpo/9eBOmzo3gO4DOgaDnyYTXCvqTQnADMlzQA6Ak8m8gdxLtm81JFzaUxSV4IBEftFHYtzqeaDJJxLU5KuAS5kw0g+5zKKt6Ccc86lJb8H5ZxzLi15gnLOOZeWPEE555xLS56gnHPOpSVPUM4559LS/wORQ1RQQpW6VQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),cbs=CB_PlotGradient()).fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def SkipNLoss(fn,n_skip=0):\n",
    "    '''Loss-Function modifier that skips the first n samples of sequential data'''\n",
    "    def _inner( input, target):\n",
    "        return fn(input[:,n_skip:],target[:,n_skip:])\n",
    "    \n",
    "    #checking if fn has the attribute name leads sometimes to false -> try_catch instead\n",
    "    try:\n",
    "        _inner.__name__ = fn.__name__\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.140427</td>\n",
       "      <td>0.085511</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=SkipNLoss(nn.MSELoss(),n_skip=30)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def fun_rmse(inp, targ): \n",
    "    '''rmse loss function defined as a function not as a AccumMetric'''\n",
    "    return torch.sqrt(F.mse_loss(inp, targ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fun_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.150300</td>\n",
       "      <td>0.137286</td>\n",
       "      <td>0.244450</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),metrics=SkipNLoss(fun_rmse,n_skip=30)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def norm_rmse(inp, targ):\n",
    "    '''rmse loss function defined as a function not as a AccumMetric'''\n",
    "    return fun_rmse(inp, targ)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>norm_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.111846</td>\n",
       "      <td>0.084827</td>\n",
       "      <td>16.277262</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),metrics=SkipNLoss(norm_rmse,n_skip=30)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mean_vaf(inp,targ):\n",
    "    return (1-((targ-inp).var()/targ.var()))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_vaf</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.103266</td>\n",
       "      <td>0.081350</td>\n",
       "      <td>87.727005</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),metrics=SkipNLoss(mean_vaf,n_skip=30)).fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Learner Models\n",
    "Create Learner with different kinds of models with fitting Parameters and regularizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_inp_out_size(db):\n",
    "    '''returns input and output size of a timeseries databunch'''\n",
    "    tup = db.one_batch()\n",
    "    inp = tup[0].shape[-1]\n",
    "    out = tup[1].shape[-1]\n",
    "    return inp,out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(get_inp_out_size(db),(2,1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Learner\n",
    "The Learners include model specific optimizations. Removing the first n_skip samples of the loss function of transient time, greatly improves training stability. In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(SimpleRNN, keep=True)\n",
    "def RNNLearner(db,loss_func=nn.MSELoss(),metrics=[fun_rmse],n_skip=0,cbs=None,**kwargs):\n",
    "    inp,out = get_inp_out_size(db)\n",
    "    model = SimpleRNN(inp,out,**kwargs)\n",
    "  \n",
    "    skip = partial(SkipNLoss,n_skip=n_skip)\n",
    "        \n",
    "    metrics= [skip(f) for f in metrics]\n",
    "    loss_func = skip(loss_func)\n",
    "        \n",
    "    lrn = Learner(db,model,loss_func=loss_func,opt_func=ranger,metrics=metrics,cbs=cbs)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fun_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.703476</td>\n",
       "      <td>5.054102</td>\n",
       "      <td>2.222403</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RNNLearner(db,rnn_type='qrnn').fit(1,3e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCN Learner\n",
    "Performs better on multi input data. Higher beta values allow a way smoother prediction. Way faster then RNNs in prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(TCN, keep=True)\n",
    "def TCNLearner(db,hl_depth=3,loss_func=nn.MSELoss(),metrics=[fun_rmse],n_skip=0,cbs=None,**kwargs):\n",
    "    inp,out = get_inp_out_size(db)\n",
    "    n_skip = 2**hl_depth if n_skip is None else n_skip\n",
    "    model = TCN(inp,out,hl_depth,**kwargs)\n",
    "  \n",
    "    skip = partial(SkipNLoss,n_skip=n_skip)\n",
    "        \n",
    "    metrics= [skip(f) for f in metrics]\n",
    "    loss_func = skip(loss_func)\n",
    "        \n",
    "    lrn = Learner(db,model,loss_func=loss_func,opt_func=ranger,metrics=metrics,cbs=cbs)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fun_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15.305682</td>\n",
       "      <td>15.278282</td>\n",
       "      <td>3.903983</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TCNLearner(db).fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRNN Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(CRNN, keep=True)\n",
    "def CRNNLearner(db,loss_func=nn.MSELoss(),metrics=[fun_rmse],n_skip=0,cbs=None,**kwargs):\n",
    "    inp,out = get_inp_out_size(db)\n",
    "    model = CRNN(inp,out,**kwargs)\n",
    "  \n",
    "    skip = partial(SkipNLoss,n_skip=n_skip)\n",
    "        \n",
    "    metrics= [skip(f) for f in metrics]\n",
    "    loss_func = skip(loss_func)\n",
    "        \n",
    "    lrn = Learner(db,model,loss_func=loss_func,opt_func=ranger,metrics=metrics,cbs=cbs)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fun_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10.440056</td>\n",
       "      <td>10.161863</td>\n",
       "      <td>3.173481</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CRNNLearner(db,rnn_type='qrnn').fit(1,3e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn = CRNNLearner(db,rnn_type='qrnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregressive Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(TCN, keep=True)\n",
    "def AR_TCNLearner(db,hl_depth=3,alpha=1,beta=1,early_stop=0,metrics=None,n_skip=None,**kwargs):\n",
    "    n_skip = 2**hl_depth if n_skip is None else n_skip\n",
    "    skip = partial(SkipNLoss,n_skip=n_skip)\n",
    "    \n",
    "    inp,out = get_inp_out_size(db)\n",
    "    model = AR_Model(TCN(inp+out,out,hl_depth,**kwargs),ar=False,rf=n_skip)\n",
    "    model.init_normalize(db.one_batch())\n",
    "    \n",
    "    cbs=[ARInitCB(),TimeSeriesRegularizer(alpha=alpha,beta=beta,modules=[model.model.conv_layers[-1]]),SaveModelCallback()]\n",
    "    if early_stop > 0:\n",
    "        cbs += [EarlyStoppingCallback(patience=early_stop)]\n",
    "        \n",
    "    if metrics is None: metrics=SkipNLoss(fun_rmse,n_skip)\n",
    "        \n",
    "    lrn = Learner(db,model,loss_func=nn.MSELoss(),opt_func=ranger,metrics=metrics,cbs=cbs)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(AR_RNN, keep=True)\n",
    "def AR_RNNLearner(db,alpha=0,beta=0,early_stop=0,metrics=None,n_skip=0,fname='model',**kwargs):\n",
    "    skip = partial(SkipNLoss,n_skip=n_skip)\n",
    "    \n",
    "    inp,out = get_inp_out_size(db)\n",
    "    model = AR_Model(AR_RNN(inp+out,out,**kwargs),ar=False,hs=True)\n",
    "    model.init_normalize(db.one_batch())\n",
    "    \n",
    "    cbs=[ARInitCB(),TimeSeriesRegularizer(alpha=alpha,beta=beta,modules=[model.model.rnn]),SaveModelCallback()]\n",
    "    if early_stop > 0:\n",
    "        cbs += [EarlyStoppingCallback(patience=early_stop)]\n",
    "        \n",
    "    if metrics is None: metrics=SkipNLoss(fun_rmse,n_skip)\n",
    "        \n",
    "    lrn = Learner(db,model,loss_func=nn.MSELoss(),opt_func=ranger,metrics=metrics,cbs=cbs)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_model.ipynb.\n",
      "Converted 02_learner.ipynb.\n",
      "Converted 03_tbptt_dl.ipynb.\n",
      "Converted 11_dualrnn.ipynb.\n",
      "Converted 12_TensorQuaternions.ipynb.\n",
      "Converted 13_PBT.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
