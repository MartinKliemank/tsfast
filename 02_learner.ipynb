{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp learner\n",
    "# default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from seqdata.core import *\n",
    "from seqdata.models.core import *\n",
    "from fastai2.basics import *\n",
    "from fastai2.callback.progress import *\n",
    "from fastai2.callback.tracker import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner\n",
    "> Pytorch Modules for Training Models for sequential data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = DataBlock(blocks=(SequenceBlock.from_hdf(['current','voltage'],TensorSequencesInput,clm_shift=[-1,-1]),\n",
    "                        SequenceBlock.from_hdf(['voltage'],TensorSequencesOutput,clm_shift=[1])),\n",
    "                 get_items=CreateDict([DfHDFCreateWindows(win_sz=1000+1,stp_sz=1000,clm='current')]),\n",
    "                 splitter=ApplyToDict(ParentSplitter()))\n",
    "db = seq.dataloaders(get_hdf_files('test_data/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13.621741</td>\n",
       "      <td>12.450136</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SimpleRNN(2,1)\n",
    "lrn = Learner(db,model,loss_func=nn.MSELoss()).fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class GradientClipping(Callback):\n",
    "    \"`Callback` cutts of the gradient of every minibtch at `clip_val`\"\n",
    "    def __init__(self, clip_val=10): self.clip_val = clip_val\n",
    "\n",
    "    def after_backward(self):\n",
    "        nn.utils.clip_grad_norm_(self.model.parameters(), self.clip_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class WeightClipping(Callback):\n",
    "    \"`Callback` that clips the weights of a given module at `clip_limit` after every iteration\"\n",
    "    def __init__(self, module, clip_limit = 1):\n",
    "        self.module = module\n",
    "        self.clip_limit = clip_limit\n",
    "\n",
    "    def after_batch(self):\n",
    "#         import pdb; pdb.set_trace()\n",
    "        for p in self.module.parameters():\n",
    "            p.data.clamp_(-self.clip_limit,self.clip_limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SkipFirstNCallback(Callback):\n",
    "    \"`Callback` skips first n samples from prediction and target, optionally `with_loss`\"\n",
    "    def __init__(self, n_skip = 0):\n",
    "        self.n_skip = n_skip\n",
    "\n",
    "    def after_pred(self):\n",
    "        self.learn.pred = self.pred[:,self.n_skip:]\n",
    "#         import pdb; pdb.set_trace()\n",
    "        if isinstance(self.yb, tuple):\n",
    "            self.learn.yb = tuple([y[:,self.n_skip:] for y in self.yb])\n",
    "        else:\n",
    "            self.learn.yb = self.yb[:,self.n_skip:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class VarySeqLen(Callback):\n",
    "    \"`Callback` varies sequence length of every mini batch\"\n",
    "    def __init__(self, min_len = 50):\n",
    "        self.min_len = min_len\n",
    "\n",
    "    def begin_batch(self):\n",
    "#         import pdb; pdb.set_trace()\n",
    "        lx = self.xb[0].shape[1]\n",
    "        ly = self.yb[0].shape[1]\n",
    "        lim = random.randint(self.min_len,ly)\n",
    "#         import pdb; pdb.set_trace()\n",
    "        if ly < lx:\n",
    "            self.learn.xb = tuple([x[:,:-(ly-lim)] for x in self.xb])\n",
    "        else:\n",
    "            self.learn.xb = tuple([x[:,:lim] for x in self.xb])\n",
    "            \n",
    "        self.learn.yb = tuple([y[:,:lim] for y in self.yb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10.049837</td>\n",
       "      <td>5.112575</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),cbs=VarySeqLen(10)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.callback.hook import *\n",
    "@delegates()\n",
    "class TimeSeriesRegularizer(HookCallback):\n",
    "    \"Callback that adds AR and TAR to the loss, calculated by output of provided layer\"\n",
    "    run_before=TrainEvalCallback\n",
    "    def __init__(self,alpha=0.0, beta=0.0,dim = None,detach=False, **kwargs):\n",
    "        super().__init__(detach=detach,**kwargs)\n",
    "        store_attr(self,'alpha,beta,dim')\n",
    "        \n",
    "    def hook(self, m, i, o): \n",
    "#         import pdb; pdb.set_trace()\n",
    "        if type(o) is torch.Tensor:\n",
    "            self.out = o\n",
    "        else:\n",
    "            self.out = o[0]\n",
    "        \n",
    "        #find time axis if not already provided\n",
    "        if self.dim is None:\n",
    "            self.dim = np.argmax([0,self.out.shape[1],self.out.shape[2]])\n",
    "    \n",
    "    def after_loss(self):\n",
    "        if not self.training: return\n",
    "        \n",
    "        h = self.out.float()\n",
    "        \n",
    "        if self.alpha != 0.:  \n",
    "            l_a = float(self.alpha) * h.pow(2).mean()\n",
    "            self.learn.loss = self.learn.loss+l_a \n",
    "            \n",
    "        if self.beta != 0. and h.shape[self.dim]>1:\n",
    "            h_diff = (h[:,1:] - h[:,:-1]) if self.dim == 1 else (h[:,:,1:] - h[:,:,:-1])\n",
    "            l_b = float(self.beta) * h_diff.pow(2).mean()\n",
    "            self.learn.loss = self.learn.loss+l_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ARInitCB(Callback):\n",
    "    '''Adds the target variable to the input tuple for autoregression'''\n",
    "    def begin_batch(self):\n",
    "#         import pdb; pdb.set_trace()\n",
    "        self.learn.xb = tuple([*self.xb,*self.yb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.478687</td>\n",
       "      <td>0.723212</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss()).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from matplotlib.lines import Line2D\n",
    "def plot_grad_flow(named_parameters):\n",
    "    '''Plots the gradients flowing through different layers in the net during training.\n",
    "    Can be used for checking for possible gradient vanishing / exploding problems.\n",
    "    *modified version of https://discuss.pytorch.org/t/check-gradient-flow-in-network/15063/8*\n",
    "    \n",
    "    Call multiple time for transparent overlays, representing the mean gradients\n",
    "    '''\n",
    "    ave_grads = []\n",
    "    max_grads= []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "#             pdb.set_trace()\n",
    "            ave_grads.append(0 if p.grad is None else p.grad.abs().mean())\n",
    "            max_grads.append(0 if p.grad is None else p.grad.abs().max())\n",
    "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
    "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(left=0, right=len(ave_grads))\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"Gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)\n",
    "    plt.yscale('log')\n",
    "    plt.tight_layout()\n",
    "    plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n",
    "                Line2D([0], [0], color=\"b\", lw=4),\n",
    "                Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CB_PlotGradient(Callback):\n",
    "    '''Plot the Gradient Distribution for every trainable parameter'''\n",
    "    def begin_fit(self,n_draws=20):\n",
    "        '''Create a new figure to plot in'''\n",
    "        self.n_draws =n_draws\n",
    "        plt.figure()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "    def after_backward(self):\n",
    "        '''plot the gradient for every layer of the current minibatch'''\n",
    "        # plotting n_draws times at the whole training\n",
    "        if self.iter % (max(self.n_epoch*self.n_iter//self.n_draws,1)) == 0:\n",
    "#         if self.iter == self.n_iter-1:\n",
    "            plot_grad_flow(self.learn.model.named_parameters())\n",
    "#             print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.276917</td>\n",
       "      <td>0.204979</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),cbs=CB_PlotGradient()).fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import functools\n",
    "\n",
    "def ignore_nan(func):\n",
    "    '''remove nan values from tensors before function execution, reduces tensor to a flat array, apply to functions such as mse'''\n",
    "    @functools.wraps(func)\n",
    "    def ignore_nan_decorator(*args, **kwargs):\n",
    "#         mask = ~torch.isnan(args[-1]) #nan mask of target tensor\n",
    "#         args = tuple([x[mask] for x in args]) #remove nan values\n",
    "        mask = ~torch.isnan(args[-1][...,-1]) #nan mask of target tensor\n",
    "        args = tuple([x[mask,:] for x in args]) #remove nan values\n",
    "        return func(*args, **kwargs)\n",
    "    return ignore_nan_decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "y_t = torch.ones(32,n,6)\n",
    "y_t[:,20]=np.nan\n",
    "y_p = torch.ones(32,n,6)*1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1000, 6])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(~torch.isnan(y_t)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1000, 6])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.isnan(mse(y_p,y_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "mse_nan = ignore_nan(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(mse_nan(y_p,y_t),0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def SkipNLoss(fn,n_skip=0):\n",
    "    '''Loss-Function modifier that skips the first n samples of sequential data'''\n",
    "    @functools.wraps(fn)\n",
    "    def _inner( input, target):\n",
    "        return fn(input[:,n_skip:],target[:,n_skip:])\n",
    "    \n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.107521</td>\n",
       "      <td>0.065476</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=SkipNLoss(nn.MSELoss(),n_skip=30)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def fun_rmse(inp, targ): \n",
    "    '''rmse loss function defined as a function not as a AccumMetric'''\n",
    "    return torch.sqrt(F.mse_loss(inp, targ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fun_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.142952</td>\n",
       "      <td>0.112645</td>\n",
       "      <td>0.236748</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),metrics=SkipNLoss(fun_rmse,n_skip=30)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def norm_rmse(inp, targ):\n",
    "    '''rmse loss function defined as a function not as a AccumMetric'''\n",
    "    return fun_rmse(inp, targ)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>norm_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.118041</td>\n",
       "      <td>0.086239</td>\n",
       "      <td>18.532928</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),metrics=SkipNLoss(norm_rmse,n_skip=30)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mean_vaf(inp,targ):\n",
    "    return (1-((targ-inp).var()/targ.var()))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_vaf</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.111325</td>\n",
       "      <td>0.076957</td>\n",
       "      <td>85.840889</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),metrics=SkipNLoss(mean_vaf,n_skip=30)).fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Learner Models\n",
    "Create Learner with different kinds of models with fitting Parameters and regularizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_inp_out_size(db):\n",
    "    '''returns input and output size of a timeseries databunch'''\n",
    "    tup = db.one_batch()\n",
    "    inp = tup[0].shape[-1]\n",
    "    out = tup[1].shape[-1]\n",
    "    return inp,out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(get_inp_out_size(db),(2,1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Learner\n",
    "The Learners include model specific optimizations. Removing the first n_skip samples of the loss function of transient time, greatly improves training stability. In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(SimpleRNN, keep=True)\n",
    "def RNNLearner(db,loss_func=nn.MSELoss(),metrics=[fun_rmse],n_skip=0,cbs=None,**kwargs):\n",
    "    inp,out = get_inp_out_size(db)\n",
    "    model = SimpleRNN(inp,out,**kwargs)\n",
    "  \n",
    "    skip = partial(SkipNLoss,n_skip=n_skip)\n",
    "        \n",
    "    metrics= [skip(f) for f in metrics]\n",
    "    loss_func = skip(loss_func)\n",
    "        \n",
    "    lrn = Learner(db,model,loss_func=loss_func,opt_func=ranger,metrics=metrics,cbs=cbs)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fun_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error building extension 'forget_mult_cuda': [1/3] /usr/local/cuda/bin/nvcc -DTORCH_EXTENSION_NAME=forget_mult_cuda -DTORCH_API_INCLUDE_EXTENSION_H -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/TH -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /home/daniel/miniconda3/envs/fastaiv2/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -std=c++11 -c /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/fastai2/text/models/forget_mult_cuda_kernel.cu -o forget_mult_cuda_kernel.cuda.o\nFAILED: forget_mult_cuda_kernel.cuda.o \n/usr/local/cuda/bin/nvcc -DTORCH_EXTENSION_NAME=forget_mult_cuda -DTORCH_API_INCLUDE_EXTENSION_H -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/TH -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /home/daniel/miniconda3/envs/fastaiv2/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -std=c++11 -c /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/fastai2/text/models/forget_mult_cuda_kernel.cu -o forget_mult_cuda_kernel.cuda.o\nIn file included from /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/THC/THC.h:4:0,\n                 from /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/fastai2/text/models/forget_mult_cuda_kernel.cu:2:\n/home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/THC/THCGeneral.h:11:10: fatal error: cublas_v2.h: No such file or directory\n #include <cublas_v2.h>\n          ^~~~~~~~~~~~~\ncompilation terminated.\n[2/3] c++ -MMD -MF forget_mult_cuda.o.d -DTORCH_EXTENSION_NAME=forget_mult_cuda -DTORCH_API_INCLUDE_EXTENSION_H -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/TH -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /home/daniel/miniconda3/envs/fastaiv2/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++11 -c /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/fastai2/text/models/forget_mult_cuda.cpp -o forget_mult_cuda.o\nninja: build stopped: subcommand failed.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_build_extension_module\u001b[0;34m(name, build_directory, verbose)\u001b[0m\n\u001b[1;32m   1065\u001b[0m                 \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuild_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m                 check=True)\n\u001b[0m\u001b[1;32m   1067\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m             raise CalledProcessError(retcode, process.args,\n\u001b[0;32m--> 512\u001b[0;31m                                      output=stdout, stderr=stderr)\n\u001b[0m\u001b[1;32m    513\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['ninja', '-v']' returned non-zero exit status 1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-2be97543e913>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRNNLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrnn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'qrnn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    188\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m;\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m;\u001b[0m                        \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m:\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                                  \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_pred'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/Development/seqdata/seqdata/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/Development/seqdata/seqdata/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, h_init)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m#         import pdb; pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhid_dp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnrm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mr_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_init\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mh_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m#residual connenction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/fastai2/text/models/qrnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, hid)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minp_bwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhid\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0mnew_hid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/fastai2/text/models/qrnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, hid)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mz_gate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf_gate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_gate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf_gate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mforget_mult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mForgetMultGPU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforget_mult_CPU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mc_gate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforget_mult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_gate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_gate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo_gate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mc_gate\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_gate\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mc_gate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_prev_x\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/fastai2/text/models/qrnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, x, f, first_h, batch_first, backward)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforget_mult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbwd_forget_mult_cuda\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mforget_mult_cuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforget_mult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/fastai2/text/models/qrnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/fastai2/text/models/qrnn.py\u001b[0m in \u001b[0;36m_build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_cpp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/fastai2/text/models/qrnn.py\u001b[0m in \u001b[0;36mload_cpp\u001b[0;34m(name, files, path)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_cpp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'qrnn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcpp_extension\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'qrnn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0mwith_cuda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m         is_python_module)\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module)\u001b[0m\n\u001b[1;32m    864\u001b[0m                     \u001b[0mbuild_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuild_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                     with_cuda=with_cuda)\n\u001b[0m\u001b[1;32m    867\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m                 \u001b[0mbaton\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_write_ninja_file_and_build\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda)\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Building extension module {}...'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m     \u001b[0m_build_extension_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_build_extension_module\u001b[0;34m(name, build_directory, verbose)\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\": {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error building extension 'forget_mult_cuda': [1/3] /usr/local/cuda/bin/nvcc -DTORCH_EXTENSION_NAME=forget_mult_cuda -DTORCH_API_INCLUDE_EXTENSION_H -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/TH -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /home/daniel/miniconda3/envs/fastaiv2/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -std=c++11 -c /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/fastai2/text/models/forget_mult_cuda_kernel.cu -o forget_mult_cuda_kernel.cuda.o\nFAILED: forget_mult_cuda_kernel.cuda.o \n/usr/local/cuda/bin/nvcc -DTORCH_EXTENSION_NAME=forget_mult_cuda -DTORCH_API_INCLUDE_EXTENSION_H -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/TH -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /home/daniel/miniconda3/envs/fastaiv2/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=sm_75 --compiler-options '-fPIC' -std=c++11 -c /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/fastai2/text/models/forget_mult_cuda_kernel.cu -o forget_mult_cuda_kernel.cuda.o\nIn file included from /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/THC/THC.h:4:0,\n                 from /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/fastai2/text/models/forget_mult_cuda_kernel.cu:2:\n/home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/THC/THCGeneral.h:11:10: fatal error: cublas_v2.h: No such file or directory\n #include <cublas_v2.h>\n          ^~~~~~~~~~~~~\ncompilation terminated.\n[2/3] c++ -MMD -MF forget_mult_cuda.o.d -DTORCH_EXTENSION_NAME=forget_mult_cuda -DTORCH_API_INCLUDE_EXTENSION_H -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/TH -isystem /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /home/daniel/miniconda3/envs/fastaiv2/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++11 -c /home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/fastai2/text/models/forget_mult_cuda.cpp -o forget_mult_cuda.o\nninja: build stopped: subcommand failed.\n"
     ]
    }
   ],
   "source": [
    "RNNLearner(db,rnn_type='qrnn').fit(1,3e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCN Learner\n",
    "Performs better on multi input data. Higher beta values allow a way smoother prediction. Way faster then RNNs in prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(TCN, keep=True)\n",
    "def TCNLearner(db,hl_depth=3,loss_func=nn.MSELoss(),metrics=[fun_rmse],n_skip=0,cbs=None,**kwargs):\n",
    "    inp,out = get_inp_out_size(db)\n",
    "    n_skip = 2**hl_depth if n_skip is None else n_skip\n",
    "    model = TCN(inp,out,hl_depth,**kwargs)\n",
    "  \n",
    "    skip = partial(SkipNLoss,n_skip=n_skip)\n",
    "        \n",
    "    metrics= [skip(f) for f in metrics]\n",
    "    loss_func = skip(loss_func)\n",
    "        \n",
    "    lrn = Learner(db,model,loss_func=loss_func,opt_func=ranger,metrics=metrics,cbs=cbs)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TCNLearner(db).fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRNN Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(CRNN, keep=True)\n",
    "def CRNNLearner(db,loss_func=nn.MSELoss(),metrics=[fun_rmse],n_skip=0,cbs=None,**kwargs):\n",
    "    inp,out = get_inp_out_size(db)\n",
    "    model = CRNN(inp,out,**kwargs)\n",
    "  \n",
    "    skip = partial(SkipNLoss,n_skip=n_skip)\n",
    "        \n",
    "    metrics= [skip(f) for f in metrics]\n",
    "    loss_func = skip(loss_func)\n",
    "        \n",
    "    lrn = Learner(db,model,loss_func=loss_func,opt_func=ranger,metrics=metrics,cbs=cbs)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRNNLearner(db,rnn_type='qrnn').fit(1,3e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn = CRNNLearner(db,rnn_type='qrnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregressive Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(TCN, keep=True)\n",
    "def AR_TCNLearner(db,hl_depth=3,alpha=1,beta=1,early_stop=0,metrics=None,n_skip=None,**kwargs):\n",
    "    n_skip = 2**hl_depth if n_skip is None else n_skip\n",
    "    skip = partial(SkipNLoss,n_skip=n_skip)\n",
    "    \n",
    "    inp,out = get_inp_out_size(db)\n",
    "    model = AR_Model(TCN(inp+out,out,hl_depth,**kwargs),ar=False,rf=n_skip)\n",
    "    model.init_normalize(db.one_batch())\n",
    "    \n",
    "    cbs=[ARInitCB(),TimeSeriesRegularizer(alpha=alpha,beta=beta,modules=[model.model.conv_layers[-1]]),SaveModelCallback()]\n",
    "    if early_stop > 0:\n",
    "        cbs += [EarlyStoppingCallback(patience=early_stop)]\n",
    "        \n",
    "    if metrics is None: metrics=SkipNLoss(fun_rmse,n_skip)\n",
    "        \n",
    "    lrn = Learner(db,model,loss_func=nn.MSELoss(),opt_func=ranger,metrics=metrics,cbs=cbs)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(AR_RNN, keep=True)\n",
    "def AR_RNNLearner(db,alpha=0,beta=0,early_stop=0,metrics=None,n_skip=0,fname='model',**kwargs):\n",
    "    skip = partial(SkipNLoss,n_skip=n_skip)\n",
    "    \n",
    "    inp,out = get_inp_out_size(db)\n",
    "    model = AR_Model(AR_RNN(inp+out,out,**kwargs),ar=False,hs=True)\n",
    "    model.init_normalize(db.one_batch())\n",
    "    \n",
    "    cbs=[ARInitCB(),TimeSeriesRegularizer(alpha=alpha,beta=beta,modules=[model.model.rnn]),SaveModelCallback()]\n",
    "    if early_stop > 0:\n",
    "        cbs += [EarlyStoppingCallback(patience=early_stop)]\n",
    "        \n",
    "    if metrics is None: metrics=SkipNLoss(fun_rmse,n_skip)\n",
    "        \n",
    "    lrn = Learner(db,model,loss_func=nn.MSELoss(),opt_func=ranger,metrics=metrics,cbs=cbs)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_models.ipynb.\n",
      "Converted 01a_IndRNN.ipynb.\n",
      "Converted 02_learner.ipynb.\n",
      "Converted 03_dataloaders.ipynb.\n",
      "Converted 11_dualrnn.ipynb.\n",
      "Converted 12_TensorQuaternions.ipynb.\n",
      "Converted 13_HPOpt.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
