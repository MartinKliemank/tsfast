{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp learner\n",
    "# default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from seqdata.core import *\n",
    "from seqdata.model import *\n",
    "from fastai2.basics import *\n",
    "from fastai2.callback.progress import *\n",
    "from fastai2.callback.tracker import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learner\n",
    "> Pytorch Modules for Training Models for sequential data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = DataBlock(blocks=(SequenceBlock.from_hdf(['current','voltage'],TensorSequencesInput,clm_shift=[-1,-1]),\n",
    "                        SequenceBlock.from_hdf(['voltage'],TensorSequencesOutput,clm_shift=[1])),\n",
    "                 get_items=CreateDict([DfHDFCreateWindows(win_sz=1000+1,stp_sz=1000,clm='current')]),\n",
    "                 splitter=ApplyToDict(ParentSplitter()))\n",
    "db = seq.dataloaders(get_hdf_files('test_data/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12.715677</td>\n",
       "      <td>11.933381</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SimpleRNN(2,1)\n",
    "lrn = Learner(db,model,loss_func=nn.MSELoss()).fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SkipFirstNCallback(Callback):\n",
    "    \"`Callback` skips first n samples from prediction and target, optionally `with_loss`\"\n",
    "    def __init__(self, n_skip = 0):\n",
    "        self.n_skip = n_skip\n",
    "\n",
    "    def after_pred(self):\n",
    "        self.learn.pred = self.pred[:,self.n_skip:]\n",
    "#         import pdb; pdb.set_trace()\n",
    "        if isinstance(self.yb, tuple):\n",
    "            self.learn.yb = tuple([y[:,self.n_skip:] for y in self.yb])\n",
    "        else:\n",
    "            self.learn.yb = self.yb[:,self.n_skip:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class VarySeqLen(Callback):\n",
    "    \"`Callback` varies sequence length of every mini batch\"\n",
    "    def __init__(self, min_len = 50):\n",
    "        self.min_len = min_len\n",
    "\n",
    "    def begin_batch(self):\n",
    "#         import pdb; pdb.set_trace()\n",
    "        lx = self.xb[0].shape[1]\n",
    "        ly = self.yb[0].shape[1]\n",
    "        lim = random.randint(self.min_len,ly)\n",
    "#         import pdb; pdb.set_trace()\n",
    "        if ly < lx:\n",
    "            self.learn.xb = tuple([x[:,:-(ly-lim)] for x in self.xb])\n",
    "        else:\n",
    "            self.learn.xb = tuple([x[:,:lim] for x in self.xb])\n",
    "            \n",
    "        self.learn.yb = tuple([y[:,:lim] for y in self.yb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10.712389</td>\n",
       "      <td>7.633007</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),cbs=VarySeqLen(10)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.callback.hook import *\n",
    "@delegates()\n",
    "class TimeSeriesRegularizer(HookCallback):\n",
    "    \"Callback that adds AR and TAR to the loss, calculated by output of provided layer\"\n",
    "    run_before=TrainEvalCallback\n",
    "    def __init__(self,alpha=0.0, beta=0.0,dim = None,detach=False, **kwargs):\n",
    "        super().__init__(detach=detach,**kwargs)\n",
    "        store_attr(self,'alpha,beta,dim')\n",
    "        \n",
    "    def hook(self, m, i, o): \n",
    "#         import pdb; pdb.set_trace()\n",
    "        if type(o) is torch.Tensor:\n",
    "            self.out = o\n",
    "        else:\n",
    "            self.out = o[0]\n",
    "        \n",
    "        #find time axis if not already provided\n",
    "        if self.dim is None:\n",
    "            self.dim = np.argmax([0,self.out.shape[1],self.out.shape[2]])\n",
    "    \n",
    "    def after_loss(self):\n",
    "        if not self.training: return\n",
    "        \n",
    "        h = self.out.float()\n",
    "        \n",
    "        if self.alpha != 0.:  \n",
    "            l_a = float(self.alpha) * h.pow(2).mean()\n",
    "            self.learn.loss = self.learn.loss+l_a \n",
    "            \n",
    "        if self.beta != 0. and h.shape[self.dim]>1:\n",
    "            h_diff = (h[:,1:] - h[:,:-1]) if self.dim == 1 else (h[:,:,1:] - h[:,:,:-1])\n",
    "            l_b = float(self.beta) * h_diff.pow(2).mean()\n",
    "            self.learn.loss = self.learn.loss+l_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ARInitCB(Callback):\n",
    "    '''Adds the target variable to the input tuple for autoregression'''\n",
    "    def begin_batch(self):\n",
    "#         import pdb; pdb.set_trace()\n",
    "        self.learn.xb = tuple([*self.xb,*self.yb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.847246</td>\n",
       "      <td>1.263071</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss()).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from matplotlib.lines import Line2D\n",
    "def plot_grad_flow(named_parameters):\n",
    "    '''Plots the gradients flowing through different layers in the net during training.\n",
    "    Can be used for checking for possible gradient vanishing / exploding problems.\n",
    "    *modified version of https://discuss.pytorch.org/t/check-gradient-flow-in-network/15063/8*\n",
    "    \n",
    "    Call multiple time for transparent overlays, representing the mean gradients\n",
    "    '''\n",
    "    ave_grads = []\n",
    "    max_grads= []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "#             pdb.set_trace()\n",
    "            ave_grads.append(0 if p.grad is None else p.grad.abs().mean())\n",
    "            max_grads.append(0 if p.grad is None else p.grad.abs().max())\n",
    "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
    "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(left=0, right=len(ave_grads))\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"Gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)\n",
    "    plt.yscale('log')\n",
    "    plt.tight_layout()\n",
    "    plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n",
    "                Line2D([0], [0], color=\"b\", lw=4),\n",
    "                Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CB_PlotGradient(Callback):\n",
    "    '''Plot the Gradient Distribution for every trainable parameter'''\n",
    "    def begin_fit(self,n_draws=20):\n",
    "        '''Create a new figure to plot in'''\n",
    "        self.n_draws =n_draws\n",
    "        plt.figure()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "    def after_backward(self):\n",
    "        '''plot the gradient for every layer of the current minibatch'''\n",
    "        # plotting n_draws times at the whole training\n",
    "        if self.iter % (max(self.n_epoch*self.n_iter//self.n_draws,1)) == 0:\n",
    "#         if self.iter == self.n_iter-1:\n",
    "            plot_grad_flow(self.learn.model.named_parameters())\n",
    "#             print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.408996</td>\n",
       "      <td>0.089067</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),cbs=CB_PlotGradient()).fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import functools\n",
    "\n",
    "def ignore_nan(func):\n",
    "    '''remove nan values from tensors before function execution, reduces tensor to a flat array, apply to functions such as mse'''\n",
    "    @functools.wraps(func)\n",
    "    def ignore_nan_decorator(*args, **kwargs):\n",
    "#         mask = ~torch.isnan(args[-1]) #nan mask of target tensor\n",
    "#         args = tuple([x[mask] for x in args]) #remove nan values\n",
    "        mask = ~torch.isnan(args[-1][...,-1]) #nan mask of target tensor\n",
    "        args = tuple([x[mask,:] for x in args]) #remove nan values\n",
    "        return func(*args, **kwargs)\n",
    "    return ignore_nan_decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "y_t = torch.ones(32,n,6)\n",
    "y_t[:,20]=np.nan\n",
    "y_p = torch.ones(32,n,6)*1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1000, 6])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(~torch.isnan(y_t)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1000, 6])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.isnan(mse(y_p,y_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "mse_nan = ignore_nan(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(mse_nan(y_p,y_t),0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def SkipNLoss(fn,n_skip=0):\n",
    "    '''Loss-Function modifier that skips the first n samples of sequential data'''\n",
    "    @functools.wraps(fn)\n",
    "    def _inner( input, target):\n",
    "        return fn(input[:,n_skip:],target[:,n_skip:])\n",
    "    \n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.105772</td>\n",
       "      <td>0.111968</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=SkipNLoss(nn.MSELoss(),n_skip=30)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def fun_rmse(inp, targ): \n",
    "    '''rmse loss function defined as a function not as a AccumMetric'''\n",
    "    return torch.sqrt(F.mse_loss(inp, targ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fun_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.120117</td>\n",
       "      <td>0.073453</td>\n",
       "      <td>0.163844</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),metrics=SkipNLoss(fun_rmse,n_skip=30)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def norm_rmse(inp, targ):\n",
    "    '''rmse loss function defined as a function not as a AccumMetric'''\n",
    "    return fun_rmse(inp, targ)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>norm_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>0.099436</td>\n",
       "      <td>23.406658</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),metrics=SkipNLoss(norm_rmse,n_skip=30)).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mean_vaf(inp,targ):\n",
    "    return (1-((targ-inp).var()/targ.var()))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>mean_vaf</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.089296</td>\n",
       "      <td>0.069476</td>\n",
       "      <td>87.974892</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Learner(db,model,loss_func=nn.MSELoss(),metrics=SkipNLoss(mean_vaf,n_skip=30)).fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Learner Models\n",
    "Create Learner with different kinds of models with fitting Parameters and regularizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_inp_out_size(db):\n",
    "    '''returns input and output size of a timeseries databunch'''\n",
    "    tup = db.one_batch()\n",
    "    inp = tup[0].shape[-1]\n",
    "    out = tup[1].shape[-1]\n",
    "    return inp,out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(get_inp_out_size(db),(2,1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Learner\n",
    "The Learners include model specific optimizations. Removing the first n_skip samples of the loss function of transient time, greatly improves training stability. In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(SimpleRNN, keep=True)\n",
    "def RNNLearner(db,loss_func=nn.MSELoss(),metrics=[fun_rmse],n_skip=0,cbs=None,**kwargs):\n",
    "    inp,out = get_inp_out_size(db)\n",
    "    model = SimpleRNN(inp,out,**kwargs)\n",
    "  \n",
    "    skip = partial(SkipNLoss,n_skip=n_skip)\n",
    "        \n",
    "    metrics= [skip(f) for f in metrics]\n",
    "    loss_func = skip(loss_func)\n",
    "        \n",
    "    lrn = Learner(db,model,loss_func=loss_func,opt_func=ranger,metrics=metrics,cbs=cbs)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fun_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.738919</td>\n",
       "      <td>5.788848</td>\n",
       "      <td>2.399956</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RNNLearner(db,rnn_type='qrnn').fit(1,3e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TCN Learner\n",
    "Performs better on multi input data. Higher beta values allow a way smoother prediction. Way faster then RNNs in prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(TCN, keep=True)\n",
    "def TCNLearner(db,hl_depth=3,loss_func=nn.MSELoss(),metrics=[fun_rmse],n_skip=0,cbs=None,**kwargs):\n",
    "    inp,out = get_inp_out_size(db)\n",
    "    n_skip = 2**hl_depth if n_skip is None else n_skip\n",
    "    model = TCN(inp,out,hl_depth,**kwargs)\n",
    "  \n",
    "    skip = partial(SkipNLoss,n_skip=n_skip)\n",
    "        \n",
    "    metrics= [skip(f) for f in metrics]\n",
    "    loss_func = skip(loss_func)\n",
    "        \n",
    "    lrn = Learner(db,model,loss_func=loss_func,opt_func=ranger,metrics=metrics,cbs=cbs)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fun_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19.012341</td>\n",
       "      <td>18.884075</td>\n",
       "      <td>4.345469</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TCNLearner(db).fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRNN Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(CRNN, keep=True)\n",
    "def CRNNLearner(db,loss_func=nn.MSELoss(),metrics=[fun_rmse],n_skip=0,cbs=None,**kwargs):\n",
    "    inp,out = get_inp_out_size(db)\n",
    "    model = CRNN(inp,out,**kwargs)\n",
    "  \n",
    "    skip = partial(SkipNLoss,n_skip=n_skip)\n",
    "        \n",
    "    metrics= [skip(f) for f in metrics]\n",
    "    loss_func = skip(loss_func)\n",
    "        \n",
    "    lrn = Learner(db,model,loss_func=loss_func,opt_func=ranger,metrics=metrics,cbs=cbs)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fun_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.348673</td>\n",
       "      <td>5.101436</td>\n",
       "      <td>2.242103</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CRNNLearner(db,rnn_type='qrnn').fit(1,3e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrn = CRNNLearner(db,rnn_type='qrnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregressive Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(TCN, keep=True)\n",
    "def AR_TCNLearner(db,hl_depth=3,alpha=1,beta=1,early_stop=0,metrics=None,n_skip=None,**kwargs):\n",
    "    n_skip = 2**hl_depth if n_skip is None else n_skip\n",
    "    skip = partial(SkipNLoss,n_skip=n_skip)\n",
    "    \n",
    "    inp,out = get_inp_out_size(db)\n",
    "    model = AR_Model(TCN(inp+out,out,hl_depth,**kwargs),ar=False,rf=n_skip)\n",
    "    model.init_normalize(db.one_batch())\n",
    "    \n",
    "    cbs=[ARInitCB(),TimeSeriesRegularizer(alpha=alpha,beta=beta,modules=[model.model.conv_layers[-1]]),SaveModelCallback()]\n",
    "    if early_stop > 0:\n",
    "        cbs += [EarlyStoppingCallback(patience=early_stop)]\n",
    "        \n",
    "    if metrics is None: metrics=SkipNLoss(fun_rmse,n_skip)\n",
    "        \n",
    "    lrn = Learner(db,model,loss_func=nn.MSELoss(),opt_func=ranger,metrics=metrics,cbs=cbs)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(AR_RNN, keep=True)\n",
    "def AR_RNNLearner(db,alpha=0,beta=0,early_stop=0,metrics=None,n_skip=0,fname='model',**kwargs):\n",
    "    skip = partial(SkipNLoss,n_skip=n_skip)\n",
    "    \n",
    "    inp,out = get_inp_out_size(db)\n",
    "    model = AR_Model(AR_RNN(inp+out,out,**kwargs),ar=False,hs=True)\n",
    "    model.init_normalize(db.one_batch())\n",
    "    \n",
    "    cbs=[ARInitCB(),TimeSeriesRegularizer(alpha=alpha,beta=beta,modules=[model.model.rnn]),SaveModelCallback()]\n",
    "    if early_stop > 0:\n",
    "        cbs += [EarlyStoppingCallback(patience=early_stop)]\n",
    "        \n",
    "    if metrics is None: metrics=SkipNLoss(fun_rmse,n_skip)\n",
    "        \n",
    "    lrn = Learner(db,model,loss_func=nn.MSELoss(),opt_func=ranger,metrics=metrics,cbs=cbs)\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_model.ipynb.\n",
      "Converted 02_learner.ipynb.\n",
      "Converted 03_dataloaders.ipynb.\n",
      "Converted 11_dualrnn.ipynb.\n",
      "Converted 12_TensorQuaternions.ipynb.\n",
      "Converted 13_HPOpt.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
