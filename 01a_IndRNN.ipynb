{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Pytorch Models for Sequential Data\n",
    "output-file: indrnn.html\n",
    "title: IndRNN\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.indrnn\n",
    "#| default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from seqdata.core import *\n",
    "from fastai.basics import *\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "#import warnings\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Function\n",
    "\n",
    "from torch.nn import Parameter\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = DataBlock(blocks=(SequenceBlock.from_hdf(['current','voltage'],TensorSequencesInput,clm_shift=[0,-1]),\n",
    "                        SequenceBlock.from_hdf(['voltage'],TensorSequencesOutput,clm_shift=[-1])),\n",
    "                 get_items=CreateDict([DfHDFCreateWindows(win_sz=100+1,stp_sz=50,clm='current')]),\n",
    "                 splitter=ApplyToDict(ParentSplitter()))\n",
    "db = seq.dataloaders(get_hdf_files(Path.cwd()/'test_data/'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IndRNN Cuda Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "IndRNN_CODE = \"\"\"\n",
    "extern \"C\" {\n",
    "\n",
    "    __forceinline__ __device__ float reluf(float x)\n",
    "    {\n",
    "        return (x > 0.f) ? x : 0.f;\n",
    "    }\n",
    "\n",
    "    __forceinline__ __device__ float calc_grad_activation(float x)\n",
    "    {\n",
    "        return (x > 0.f) ? 1.f : 0.f;\n",
    "    }\n",
    "\n",
    "    __global__ void indrnn_fwd( const float * __restrict__ x,\n",
    "                            const float * __restrict__ weight_hh, const float * __restrict__ h0,\n",
    "                            const int len, const int batch, const int hidden_size, \n",
    "                            float * __restrict__ h)\n",
    "    {\n",
    "        int ncols = batch*hidden_size;\n",
    "        int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "        if (col >= ncols) return;       \n",
    "        const float weight_hh_cur = *(weight_hh + (col%hidden_size));\n",
    "        float cur = *(h0 + col);\n",
    "        const float *xp = x+col;\n",
    "        float *hp = h+col;\n",
    "\n",
    "        for (int row = 0; row < len; ++row)\n",
    "        {\n",
    "            cur=reluf(cur*weight_hh_cur+(*xp));\n",
    "            *hp=cur;\n",
    "            xp += ncols;\n",
    "            hp += ncols;            \n",
    "        }\n",
    "    }\n",
    "\n",
    "    __global__ void indrnn_bwd(const float * __restrict__ x,\n",
    "                             const float * __restrict__ weight_hh, const float * __restrict__ h0,\n",
    "                             const float * __restrict__ h,\n",
    "                            const float * __restrict__ grad_h, \n",
    "                            const int len, const int batch, const int hidden_size, \n",
    "                            float * __restrict__ grad_x,\n",
    "                            float * __restrict__ grad_weight_hh, float * __restrict__ grad_h0)\n",
    "    {    \n",
    "        int ncols = batch*hidden_size;\n",
    "        int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "        if (col >= ncols) return;        \n",
    "        const float weight_hh_cur = *(weight_hh + (col%hidden_size));\n",
    "        float gweight_hh_cur = 0;\n",
    "        float cur = 0;  // *(grad_last + col);        //0; strange gradient behavior. grad_last and grad_h, one of them is zero.     \n",
    "        \n",
    "        const float *xp = x+col + (len-1)*ncols;\n",
    "        const float *hp = h+col + (len-1)*ncols;      \n",
    "        float *gxp = grad_x + col + (len-1)*ncols;\n",
    "        const float *ghp = grad_h + col + (len-1)*ncols;\n",
    "        \n",
    "\n",
    "        for (int row = len-1; row >= 0; --row)\n",
    "        {        \n",
    "            const float prev_h_val = (row>0) ? (*(hp-ncols)) : (*(h0+col));\n",
    "            //float h_val_beforeact = prev_h_val*weight_hh_cur+(*xp);\n",
    "            float gh_beforeact = ((*ghp) + cur)*calc_grad_activation(prev_h_val*weight_hh_cur+(*xp));\n",
    "            cur = gh_beforeact*weight_hh_cur;\n",
    "            gweight_hh_cur += gh_beforeact*prev_h_val;\n",
    "            *gxp = gh_beforeact;\n",
    "\n",
    "            xp -= ncols;\n",
    "            hp -= ncols;\n",
    "            gxp -= ncols;\n",
    "            ghp -= ncols;        \n",
    "        }\n",
    "\n",
    "        atomicAdd(grad_weight_hh + (col%hidden_size), gweight_hh_cur);\n",
    "        *(grad_h0 +col) = cur;\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90090/2798395804.py:9: UserWarning: Failed to import pynvrtc and cupy for indrnn model\n",
      "  warnings.warn('Failed to import pynvrtc and cupy for indrnn model')\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import warnings\n",
    "\n",
    "\n",
    "try:\n",
    "    from cupy.cuda import function\n",
    "    from pynvrtc.compiler import Program\n",
    "except:\n",
    "    warnings.warn('Failed to import pynvrtc and cupy for indrnn model')\n",
    "\n",
    "def _get_indrnn_cuda(device):\n",
    "    if not hasattr(_get_indrnn_cuda, '_DEVICE2FUNC'):_get_indrnn_cuda._DEVICE2FUNC = {}\n",
    "    res = _get_indrnn_cuda._DEVICE2FUNC.get(device, None)\n",
    "    if res:\n",
    "        return res\n",
    "    else:\n",
    "        print ('IndRNN loaded for gpu {}'.format(device))\n",
    "        mod = function.Module()\n",
    "        mod.load(bytes(Program(IndRNN_CODE, 'indrnn_prog.cu').compile().encode()))\n",
    "        fwd_func = mod.get_function('indrnn_fwd')\n",
    "        bwd_func = mod.get_function('indrnn_bwd')\n",
    "\n",
    "        Stream = namedtuple('Stream', ['ptr'])\n",
    "        current_stream = Stream(ptr=torch.cuda.current_stream().cuda_stream)\n",
    "\n",
    "        _get_indrnn_cuda._DEVICE2FUNC[device] = (current_stream, fwd_func, bwd_func)\n",
    "        return current_stream, fwd_func, bwd_func\n",
    "\n",
    "class IndRNN_Compute_GPU(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, weight_hh, h0):\n",
    "        length = x.size(0) if x.dim() == 3 else 1\n",
    "        batch = x.size(-2)\n",
    "        hidden_size = x.size(-1)  #hidden_size\n",
    "        ncols = batch*hidden_size\n",
    "        thread_per_block = min(512, ncols)\n",
    "        num_block = (ncols-1)//thread_per_block+1\n",
    "        \n",
    "        size = (length, batch, hidden_size) if x.dim() == 3 else (batch, hidden_size)\n",
    "        h = x.new(*size)\n",
    "\n",
    "        stream, fwd_func, _ = _get_indrnn_cuda(x.device)\n",
    "        FUNC = fwd_func\n",
    "        FUNC(args=[\n",
    "            x.contiguous().data_ptr(),\n",
    "            weight_hh.contiguous().data_ptr(),\n",
    "            h0.contiguous().data_ptr(),\n",
    "            length,\n",
    "            batch,\n",
    "            hidden_size,\n",
    "            h.contiguous().data_ptr()],\n",
    "            block = (thread_per_block,1,1), grid = (num_block,1,1),\n",
    "            stream=stream\n",
    "        )\n",
    "\n",
    "        ctx.save_for_backward(x, h, weight_hh, h0)#\n",
    "        return h\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_h):\n",
    "        x, h, weight_hh, h0 = ctx.saved_tensors\n",
    "        length = x.size(0) if x.dim() == 3 else 1\n",
    "        batch = x.size(-2)\n",
    "        hidden_size = x.size(-1)#self.hidden_size\n",
    "        ncols = batch*hidden_size\n",
    "        thread_per_block = min(512, ncols)\n",
    "        num_block = (ncols-1)//thread_per_block+1\n",
    "\n",
    "        grad_x = x.new(*x.size())\n",
    "        grad_weight_hh = x.new(hidden_size).zero_()\n",
    "        grad_h0 = x.new(batch, hidden_size)  \n",
    "\n",
    "        stream, _, bwd_func = _get_indrnn_cuda(x.device)\n",
    "        FUNC = bwd_func\n",
    "        FUNC(args=[\n",
    "            x.contiguous().data_ptr(),\n",
    "            weight_hh.contiguous().data_ptr(),\n",
    "            h0.contiguous().data_ptr(),\n",
    "            h.contiguous().data_ptr(),\n",
    "            grad_h.contiguous().data_ptr(),\n",
    "            length,\n",
    "            batch,\n",
    "            hidden_size,\n",
    "            grad_x.contiguous().data_ptr(),\n",
    "            grad_weight_hh.contiguous().data_ptr(),\n",
    "            grad_h0.contiguous().data_ptr()],\n",
    "            block = (thread_per_block,1,1), grid = (num_block,1,1),\n",
    "            stream=stream\n",
    "        )\n",
    "        return grad_x, grad_weight_hh, grad_h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class IndRNN_onlyrecurrent(nn.Module):\n",
    "    def __init__(self, hidden_size, recurrent_init=None):\n",
    "        super(IndRNN_onlyrecurrent, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.recurrent_init = recurrent_init\n",
    "        self.weight_hh = Parameter(torch.Tensor(hidden_size))        \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for name, weight in self.named_parameters():\n",
    "            if \"weight_hh\" in name: nn.init.uniform_(weight, a=0, b=1)\n",
    "\n",
    "    def forward(self, input, h0=None):\n",
    "        assert input.dim() == 2 or input.dim() == 3        \n",
    "        if h0 is None:\n",
    "            h0 = input.data.new(input.size(-2),input.size(-1)).zero_()\n",
    "        elif (h0.size(-1)!=input.size(-1)) or (h0.size(-2)!=input.size(-2)):\n",
    "            raise RuntimeError(\n",
    "                'The initial hidden size must be equal to input_size. Expected {}, got {}'.format(\n",
    "                    h0.size(), input.size()))\n",
    "        IndRNN_Compute = IndRNN_Compute_GPU.apply\n",
    "        #h=IndRNN_Compute(input, self.weight_hh, h0)\n",
    "        return IndRNN_Compute(input, self.weight_hh, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Linear_overtime_module(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,bias=True):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_size, hidden_size, bias=bias)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x.contiguous().view(-1, self.input_size)\n",
    "        y = self.fc(y)\n",
    "        y = y.view(x.size()[0], x.size()[1], self.hidden_size)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# from seqdata.models.core import SeqLinear\n",
    "class IndRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1,batch_first=True):\n",
    "        super().__init__()        \n",
    "        self.batch_first = batch_first\n",
    "        \n",
    "#         self.list_linear=nn.ModuleList([SeqLinear(input_size if i == 0 else hidden_size, hidden_size,hidden_layer=0) for i in range(num_layers)])\n",
    "        self.list_linear=nn.ModuleList([Linear_overtime_module(input_size if i == 0 else hidden_size, hidden_size) for i in range(num_layers)])\n",
    "        self.list_rnn = nn.ModuleList([IndRNN_onlyrecurrent(hidden_size) for i in range(num_layers)])     \n",
    "            \n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight_hh' in name:\n",
    "                param.data.uniform_(0,0.99)            \n",
    "            if ('list_linear' in name) and 'weight' in name:#'denselayer' in name and \n",
    "                nn.init.kaiming_uniform_(param, a=8, mode='fan_in')#\n",
    "            if 'bias' in name:\n",
    "                param.data.fill_(0.0)\n",
    "    \n",
    "    def forward(self, inp, hid=None):\n",
    "#         import pdb;pdb.set_trace()\n",
    "        new_hid = []\n",
    "        if self.batch_first: inp = inp.transpose(0,1)\n",
    "        for i, (lin,rnn) in enumerate(zip(self.list_linear,self.list_rnn)):\n",
    "            inp = lin(inp)\n",
    "            inp = rnn(inp , None if hid is None else hid[i])\n",
    "            new_hid.append(inp[-1])\n",
    "            \n",
    "        if self.batch_first: inp = inp.transpose(0,1)\n",
    "        return inp, torch.stack(new_hid, 0)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndRNN loaded for gpu cuda:0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Program' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m SimpleIndRNN(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m lrn \u001b[38;5;241m=\u001b[39m \u001b[43mLearner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMSELoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_fastai/lib/python3.10/site-packages/fastai/learner.py:264\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mset_hypers(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lr)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch \u001b[38;5;241m=\u001b[39m n_epoch\n\u001b[0;32m--> 264\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelFitException\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_cleanup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_fastai/lib/python3.10/site-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/env_fastai/lib/python3.10/site-packages/fastai/learner.py:253\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch):\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;241m=\u001b[39mepoch\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelEpochException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_fastai/lib/python3.10/site-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/env_fastai/lib/python3.10/site-packages/fastai/learner.py:247\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_epoch_validate()\n",
      "File \u001b[0;32m~/miniconda3/envs/env_fastai/lib/python3.10/site-packages/fastai/learner.py:239\u001b[0m, in \u001b[0;36mLearner._do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch_train\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelTrainException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_fastai/lib/python3.10/site-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/env_fastai/lib/python3.10/site-packages/fastai/learner.py:205\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_batches\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl)\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_fastai/lib/python3.10/site-packages/fastai/learner.py:235\u001b[0m, in \u001b[0;36mLearner.one_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    233\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_device(b)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(b)\n\u001b[0;32m--> 235\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_one_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelBatchException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_fastai/lib/python3.10/site-packages/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m~/miniconda3/envs/env_fastai/lib/python3.10/site-packages/fastai/learner.py:216\u001b[0m, in \u001b[0;36mLearner._do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_one_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_pred\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myb):\n",
      "File \u001b[0;32m~/miniconda3/envs/env_fastai/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m, in \u001b[0;36mSimpleIndRNN.forward\u001b[0;34m(self, x, h_init)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, h_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m----> 9\u001b[0m     out,_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mh_init\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal(out)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/env_fastai/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[16], line 29\u001b[0m, in \u001b[0;36mIndRNN.forward\u001b[0;34m(self, inp, hid)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (lin,rnn) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlist_linear,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlist_rnn)):\n\u001b[1;32m     28\u001b[0m     inp \u001b[38;5;241m=\u001b[39m lin(inp)\n\u001b[0;32m---> 29\u001b[0m     inp \u001b[38;5;241m=\u001b[39m \u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhid\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     new_hid\u001b[38;5;241m.\u001b[39mappend(inp[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first: inp \u001b[38;5;241m=\u001b[39m inp\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/env_fastai/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[14], line 24\u001b[0m, in \u001b[0;36mIndRNN_onlyrecurrent.forward\u001b[0;34m(self, input, h0)\u001b[0m\n\u001b[1;32m     22\u001b[0m IndRNN_Compute \u001b[38;5;241m=\u001b[39m IndRNN_Compute_GPU\u001b[38;5;241m.\u001b[39mapply\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#h=IndRNN_Compute(input, self.weight_hh, h0)\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndRNN_Compute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_hh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh0\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/env_fastai/lib/python3.10/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 43\u001b[0m, in \u001b[0;36mIndRNN_Compute_GPU.forward\u001b[0;34m(ctx, x, weight_hh, h0)\u001b[0m\n\u001b[1;32m     40\u001b[0m size \u001b[38;5;241m=\u001b[39m (length, batch, hidden_size) \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (batch, hidden_size)\n\u001b[1;32m     41\u001b[0m h \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;241m*\u001b[39msize)\n\u001b[0;32m---> 43\u001b[0m stream, fwd_func, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_get_indrnn_cuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m FUNC \u001b[38;5;241m=\u001b[39m fwd_func\n\u001b[1;32m     45\u001b[0m FUNC(args\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     46\u001b[0m     x\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mdata_ptr(),\n\u001b[1;32m     47\u001b[0m     weight_hh\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mdata_ptr(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream\n\u001b[1;32m     55\u001b[0m )\n",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m, in \u001b[0;36m_get_indrnn_cuda\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndRNN loaded for gpu \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(device))\n\u001b[1;32m     18\u001b[0m mod \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mModule()\n\u001b[0;32m---> 19\u001b[0m mod\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mbytes\u001b[39m(\u001b[43mProgram\u001b[49m(IndRNN_CODE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindrnn_prog.cu\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcompile()\u001b[38;5;241m.\u001b[39mencode()))\n\u001b[1;32m     20\u001b[0m fwd_func \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39mget_function(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindrnn_fwd\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m bwd_func \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39mget_function(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindrnn_bwd\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Program' is not defined"
     ]
    }
   ],
   "source": [
    "class SimpleIndRNN(nn.Module):\n",
    "    \n",
    "    @delegates(IndRNN, keep=True)\n",
    "    def __init__(self,input_size,output_size,num_layers=1,hidden_size=100,linear_layers=0,**kwargs):\n",
    "        super().__init__()\n",
    "        self.rnn = IndRNN(input_size=input_size,hidden_size=hidden_size,num_layers=num_layers,**kwargs)\n",
    "        self.final = Linear_overtime_module(hidden_size,output_size)\n",
    "    def forward(self, x, h_init=None):\n",
    "        out,_ = self.rnn(x,h_init)\n",
    "        out = self.final(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = SimpleIndRNN(2,1,4)\n",
    "lrn = Learner(db,model,loss_func=nn.MSELoss()).fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class IndRNNRegularizer(Callback):\n",
    "    \"Callback that adds ||max(0,|U|-U_bound)|| to the loss, only useful for IndRNN\"\n",
    "    run_before=TrainEvalCallback\n",
    "    def __init__(self, clip_limit = 0.99):\n",
    "        super().__init__()\n",
    "        self.clip_limit = clip_limit\n",
    "        self.zero = None\n",
    "        \n",
    "    def after_loss(self):\n",
    "#         ||max(0,|U|-U_bound)||\n",
    "        if not self.training: return\n",
    "        if self.zero is None: self.zero = list(self.model.parameters())[0].new_tensor(0.)\n",
    "        \n",
    "        for m in self.model.modules():\n",
    "            if type(m) == IndRNN_onlyrecurrent:\n",
    "#                 import pdb;pdb.set_trace()\n",
    "                self.learn.loss_grad += torch.max(self.zero,m.weight_hh.abs()-self.clip_limit).norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_models.ipynb.\n",
      "Converted 01a_IndRNN.ipynb.\n",
      "Converted 02_learner.ipynb.\n",
      "Converted 03_dataloaders.ipynb.\n",
      "Converted 11_dualrnn.ipynb.\n",
      "Converted 12_TensorQuaternions.ipynb.\n",
      "Converted 13_HPOpt.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "from nbdev.export import *\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
