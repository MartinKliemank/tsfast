{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tbptt\n",
    "# default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%load_ext line_profiler\n",
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from seqdata.core import *\n",
    "from seqdata.model import *\n",
    "from fastai2.basics import *\n",
    "from fastai2.callback.progress import *\n",
    "from fastai2.callback.tracker import *\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TBPTT Dataloader\n",
    "> Pytorch Modules for Training Models for sequential data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tbptt dataloader needs to split the minibatches that are created in several smaller minibatches that will be returned sequentially before the next minibatch may be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delegates()\n",
    "class TbpttDl(TfmdDL):\n",
    "    def __init__(self, dataset, sub_seq_len=None, seq_len = None ,shuffle=True,num_workers=0, **kwargs):\n",
    "        self.n_sub_seq = None\n",
    "        super().__init__(dataset=dataset, shuffle=shuffle, num_workers=num_workers, **kwargs)\n",
    "        if seq_len is None: seq_len = self.do_item(0)[0].shape[0]\n",
    "        store_attr(self,'sub_seq_len,seq_len')\n",
    "        \n",
    "        if sub_seq_len is not None: self.n_sub_seq = math.ceil(seq_len / sub_seq_len)\n",
    "        self.rnn_reset = False\n",
    "        \n",
    "    def __len__(self):\n",
    "#         import pdb; pdb.set_trace()\n",
    "        if self.n_sub_seq is None:\n",
    "            return super().__len__()\n",
    "        else:\n",
    "            return super().__len__()*self.n_sub_seq\n",
    "    \n",
    "    def create_batches(self, samps):\n",
    "        batch_iter = super().create_batches(samps)\n",
    "        if self.n_sub_seq is None:\n",
    "            return batch_iter\n",
    "        else:\n",
    "            return self._tbptt_generator(batch_iter)\n",
    "        \n",
    "    def _tbptt_generator(self,batch_iter):\n",
    "        for b in batch_iter:\n",
    "            for i in range(self.n_sub_seq):\n",
    "                self.rnn_reset = i == 0\n",
    "#                 import pdb; pdb.set_trace()\n",
    "                trunc_b = tuple([x[:,i*self.sub_seq_len:(i+1)*self.sub_seq_len] for x in b])\n",
    "                yield trunc_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = DataBlock(blocks=(SequenceBlock.from_hdf(['current','voltage'],TensorSequencesInput,clm_shift=[-1,-1]),\n",
    "                        SequenceBlock.from_hdf(['voltage'],TensorSequencesOutput,clm_shift=[1])),\n",
    "                 get_items=CreateDict([DfHDFCreateWindows(win_sz=100+1,stp_sz=1000,clm='current')]),\n",
    "                 splitter=ApplyToDict(ParentSplitter()))\n",
    "seq.dl_type=TbpttDl\n",
    "db = seq.dataloaders(get_hdf_files('test_data/'),sub_seq_len=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 90, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.one_batch()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_workers has to be 0. If there are parallel workers, the order of minibatches will be corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 90, 2])\n",
      "torch.Size([64, 10, 2])\n",
      "torch.Size([64, 90, 2])\n",
      "torch.Size([64, 10, 2])\n",
      "torch.Size([64, 90, 2])\n",
      "torch.Size([64, 10, 2])\n",
      "torch.Size([64, 90, 2])\n",
      "torch.Size([64, 10, 2])\n",
      "torch.Size([64, 90, 2])\n",
      "torch.Size([64, 10, 2])\n",
      "torch.Size([64, 90, 2])\n",
      "torch.Size([64, 10, 2])\n",
      "torch.Size([64, 90, 2])\n",
      "torch.Size([64, 10, 2])\n",
      "torch.Size([64, 90, 2])\n",
      "torch.Size([64, 10, 2])\n"
     ]
    }
   ],
   "source": [
    "for x in db.train:\n",
    "    print(x[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TBPTT_Reset_Callback\n",
    "The stateful model needs to reset its hidden state, when a new sequence begins. The callback reads the reset flag and acts accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TbpttResetCB(Callback):\n",
    "    \"`Callback` resets the rnn model with every new sequence for tbptt\"\n",
    "        \n",
    "    def begin_batch(self):\n",
    "        dl = self.learn.data.train if self.training else self.learn.data.valid\n",
    "        if hasattr(dl,'rnn_reset')and dl.rnn_reset: self.model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_model.ipynb.\n",
      "Converted 02_learner.ipynb.\n",
      "Converted 03_tbptt_dl.ipynb.\n",
      "Converted 11_ProDiag.ipynb.\n",
      "Converted 12_TensorQuaternions.ipynb.\n",
      "Converted 13_PBT.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
