{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp hpopt\n",
    "# default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext line_profiler\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization Module\n",
    "> Pytorch Models for Sequential Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from seqdata.core import *\n",
    "from seqdata.models.core import *\n",
    "from seqdata.learner import *\n",
    "from fastai2.basics import *\n",
    "from fastai2.callback.schedule import *\n",
    "from fastai2.callback.rnn import *\n",
    "from fastai2.callback.tracker import *\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import Trainable\n",
    "from ray.tune.schedulers import *\n",
    "from ray.tune.trial import ExportFormat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_paths = '/mnt/data/Systemidentification/WienerHammerstein/'\n",
    "hdf_files = L([f for f in get_hdf_files(f_paths) if 'test' not in str(f)])\n",
    "tfm_src = CreateDict([DfHDFCreateWindows(win_sz=400,stp_sz=100,clm='u')])\n",
    "dls = DataBlock(blocks=(SequenceBlock.from_hdf(['u'],TensorSequencesInput),\n",
    "                        SequenceBlock.from_hdf(['y'],TensorSequencesOutput)),\n",
    "                get_items=tfm_src,\n",
    "                splitter=ApplyToDict(FuncSplitter(lambda o: 'valid' in str(o)))).dataloaders(hdf_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need a log uniform distibution for variables with vast value ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def log_uniform(min_bound, max_bound, base=10):\n",
    "    '''uniform sampling in an exponential range'''\n",
    "    logmin = np.log(min_bound) / np.log(base)\n",
    "    logmax = np.log(max_bound) / np.log(base)\n",
    "    def _sample():\n",
    "        return base**(np.random.uniform(logmin, logmax))\n",
    "    return _sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0006705651619449839,\n",
       " 3.033112015022537e-07,\n",
       " 1.9762028258780075e-07,\n",
       " 0.0014911616745581977,\n",
       " 9.689375387920038e-06]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[log_uniform(1e-8, 1e-2)() for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LearnerTrainable(tune.Trainable):\n",
    "\n",
    "    def _setup(self, config):\n",
    "        self.create_lrn = ray.get(config['create_lrn'])\n",
    "        self.dls = ray.get(config['dls'])\n",
    "\n",
    "        self.lrn = self.create_lrn(self.dls,config)\n",
    "\n",
    "    def _train(self):\n",
    "        with self.lrn.no_bar(): self.lrn.fit(1)\n",
    "        train_loss,valid_loss,rmse = self.lrn.recorder.values[-1]\n",
    "        return {'train_loss': train_loss,\n",
    "                'valid_loss': valid_loss,\n",
    "                'mean_loss': rmse}\n",
    "\n",
    "    def _save(self, checkpoint_dir):\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, \"model.pth\")\n",
    "        torch.save(self.lrn.model.state_dict(), checkpoint_path)\n",
    "        return checkpoint_path\n",
    "\n",
    "    def _restore(self, checkpoint_path):\n",
    "        self.lrn.model.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "    def _export_model(self, export_formats, export_dir):\n",
    "        if export_formats == [ExportFormat.MODEL]:\n",
    "            path = os.path.join(export_dir, \"exported_model\")\n",
    "            torch.save(self.lrn.model.state_dict(), path)\n",
    "            return {ExportFormat.MODEL: path}\n",
    "        else:\n",
    "            raise ValueError(\"unexpected formats: \" + str(export_formats))\n",
    "\n",
    "    # the learner class will be recreated with every perturbation, saving the model\n",
    "    # that way the new hyperparameter will be applied\n",
    "    def reset_config(self, new_config):\n",
    "        model_state = self.lrn.model.state_dict()\n",
    "#         import pdb; pdb.set_trace()\n",
    "        self.lrn = self.create_lrn(self.dls,new_config)\n",
    "        \n",
    "        #restore trainable parameters, keeping the new hyperparameters in the model like dropout\n",
    "        self.lrn.model.load_state_dict(model_state)\n",
    "        \n",
    "        self.config = new_config\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.callback.tracker import SaveModelCallback \n",
    "def learner_optimize(config, checkpoint_dir=None):\n",
    "        create_lrn = ray.get(config['create_lrn'])\n",
    "        dls = ray.get(config['dls'])\n",
    "        \n",
    "        #Scheduling Parameters for training the Model\n",
    "        lrn_kwargs = {'n_epoch':100,'pct_start':0.5}\n",
    "        for attr in ['n_epoch','pct_start']:\n",
    "            if attr in config: lrn_kwargs[attr] = config[attr]\n",
    "\n",
    "        lrn = create_lrn(dls,config)\n",
    "        lrn.lr = config['lr'] if 'lr' in config else 3e-3\n",
    "        lrn.add_cb(CBRayReporter() if 'reporter' not in config else ray.get(config['reporter'])())\n",
    "        lrn.add_cb(SaveModelCallback())\n",
    "        with lrn.no_bar(): \n",
    "            ray.get(config['fit_method'])(lrn,**lrn_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mutation config dictionary consists of functions that sample from a distribution. In order to retrieve a dictionary with one realisation we need the function sample_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sample_config(config):\n",
    "    ret_conf = config.copy()\n",
    "    for k in ret_conf:\n",
    "        ret_conf[k]=ret_conf[k]()\n",
    "    return ret_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CBRayReporter(Callback):\n",
    "    \"`Callback` reports progress after every epoch to the ray tune logger\"\n",
    "\n",
    "    def after_epoch(self):\n",
    "        train_loss,valid_loss,rmse = self.learn.recorder.values[-1]\n",
    "        tune.report(train_loss=train_loss,\n",
    "                        valid_loss=valid_loss,\n",
    "                        mean_loss=rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HPOptimizer():\n",
    "    def __init__(self,create_lrn,dls):\n",
    "        self.create_lrn = create_lrn\n",
    "        self.dls = dls\n",
    "        self.analysis = None\n",
    "    \n",
    "    @delegates(ray.init)\n",
    "    def start_ray(self,**kwargs):\n",
    "        ray.shutdown()\n",
    "        ray.init(**kwargs)\n",
    "        \n",
    "    def stop_ray(self):\n",
    "        ray.shutdown()\n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "    @delegates(tune.run, keep=True)\n",
    "    def optimize(self,config,optimize_func=learner_optimize,resources_per_trial={\"gpu\": 1.0},verbose=1,**kwargs):\n",
    "        config['create_lrn'] = ray.put(self.create_lrn)\n",
    "        #dls are large objects, letting ray handle the copying process makes it much faster\n",
    "        config['dls'] = ray.put(self.dls) \n",
    "        if 'fit_method' not in config: config['fit_method'] = ray.put(Learner.fit_flat_cos)\n",
    "\n",
    "        self.analysis = tune.run(\n",
    "            optimize_func,\n",
    "            config=config,\n",
    "            resources_per_trial=resources_per_trial,\n",
    "            verbose=verbose,\n",
    "            **kwargs)\n",
    "        return self.analysis\n",
    "        \n",
    "    @delegates(tune.run, keep=True)\n",
    "    def optimize_pbt(self,opt_name,num_samples,config,mut_conf,freq=2,\n",
    "                 stop={\"training_iteration\": 40 },\n",
    "                 resources_per_trial={\"gpu\": 1 },\n",
    "                 resample_probability=0.25,\n",
    "                 quantile_fraction=0.25,\n",
    "                 **kwargs):\n",
    "        self.mut_conf = mut_conf\n",
    "        \n",
    "        config['create_lrn'] = ray.put(self.create_lrn)\n",
    "        #dls are large objects, letting ray handle the copying process makes it much faster\n",
    "        config['dls'] = ray.put(self.dls) \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        scheduler = PopulationBasedTraining(\n",
    "        time_attr=\"training_iteration\",\n",
    "        metric=\"mean_loss\",\n",
    "        mode=\"min\",\n",
    "        perturbation_interval=freq,\n",
    "        resample_probability=resample_probability,\n",
    "        quantile_fraction=quantile_fraction,\n",
    "        hyperparam_mutations=mut_conf)\n",
    "        \n",
    "        self.analysis = tune.run(\n",
    "            LearnerTrainable,\n",
    "            name=opt_name,\n",
    "            scheduler=scheduler,\n",
    "            reuse_actors=True,\n",
    "            verbose=1,\n",
    "            stop=stop,\n",
    "            checkpoint_score_attr=\"mean_loss\",\n",
    "            checkpoint_freq=freq,\n",
    "            keep_checkpoints_num=4,\n",
    "            num_samples=num_samples,\n",
    "            resources_per_trial=resources_per_trial,\n",
    "            config=config,\n",
    "            **kwargs)\n",
    "        return self.analysis\n",
    "    \n",
    "    def best_model(self):\n",
    "        if self.analysis is None: raise Exception\n",
    "        model = self.create_lrn(self.dls,sample_config(self.mut_conf)).model\n",
    "        f_path = self.analysis.get_best_trial('mean_loss').checkpoint.value\n",
    "        model.load_state_dict(torch.load(f_path))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Population Based Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lrn(dls,config):\n",
    "    lr = config['lr']\n",
    "    alpha = config['alpha']\n",
    "    beta = config['beta']\n",
    "    weight_p = config['weight_p']\n",
    "    \n",
    "    lrn = RNNLearner(dls,cbs=[TimeSeriesRegularizer(alpha,beta)],weight_p=weight_p)\n",
    "    lrn.lr = lr\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 13.7/125.8 GiB<br>PopulationBasedTraining: 2 checkpoints, 1 perturbs<br>Resources requested: 0/64 CPUs, 0.0/2 GPUs, 0.0/75.83 GiB heap, 0.0/25.15 GiB objects (0/1.0 accelerator_type:RTX)<br>Result logdir: /mnt/data/ray_results/pbt_test<br>Number of trials: 4 (4 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">     alpha</th><th style=\"text-align: right;\">      beta</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  weight_p</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  valid_loss</th><th style=\"text-align: right;\">  neg_mean_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>LearnerTrainable_35897_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.00277347</td><td style=\"text-align: right;\">0.00580332</td><td style=\"text-align: right;\">0.00189658 </td><td style=\"text-align: right;\">  0.286271</td><td style=\"text-align: right;\">0.245653</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         8.01477</td><td style=\"text-align: right;\">   0.0551403</td><td style=\"text-align: right;\">   0.060397 </td><td style=\"text-align: right;\">      -0.245653</td></tr>\n",
       "<tr><td>LearnerTrainable_35897_00001</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.552176  </td><td style=\"text-align: right;\">0.0318722 </td><td style=\"text-align: right;\">0.0010794  </td><td style=\"text-align: right;\">  0.163314</td><td style=\"text-align: right;\">0.245539</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         7.79972</td><td style=\"text-align: right;\">   0.055529 </td><td style=\"text-align: right;\">   0.0603454</td><td style=\"text-align: right;\">      -0.245539</td></tr>\n",
       "<tr><td>LearnerTrainable_35897_00002</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">1.59938   </td><td style=\"text-align: right;\">6.62838   </td><td style=\"text-align: right;\">0.000283733</td><td style=\"text-align: right;\">  0.133931</td><td style=\"text-align: right;\">0.246883</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         8.05359</td><td style=\"text-align: right;\">   0.0572483</td><td style=\"text-align: right;\">   0.0610083</td><td style=\"text-align: right;\">      -0.246883</td></tr>\n",
       "<tr><td>LearnerTrainable_35897_00003</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">0.00346684</td><td style=\"text-align: right;\">0.0048361 </td><td style=\"text-align: right;\">0.00158048 </td><td style=\"text-align: right;\">  0.357838</td><td style=\"text-align: right;\">0.2447  </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         7.89004</td><td style=\"text-align: right;\">   0.0548479</td><td style=\"text-align: right;\">   0.0599264</td><td style=\"text-align: right;\">      -0.2447  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f41b1883850>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\n",
    "            \"lr\": tune.loguniform(1e-2, 1e-4),\n",
    "            \"alpha\": tune.loguniform(1e-5, 10),\n",
    "            \"beta\": tune.loguniform(1e-5, 10),\n",
    "            \"weight_p\": tune.uniform(0, 0.5)}\n",
    "mut_conf = {# distribution for resampling\n",
    "            \"lr\": log_uniform(1e-8, 1e-2),\n",
    "            \"alpha\": log_uniform(1e-5, 10),\n",
    "            \"beta\": log_uniform(1e-5, 10),\n",
    "            \"weight_p\": lambda: np.random.uniform(0, 0.5)}\n",
    "\n",
    "hp_opt = HPOptimizer(create_lrn,dls)\n",
    "hp_opt.start_ray()\n",
    "hp_opt.optimize_pbt('pbt_test',4,config,mut_conf,freq=1,\n",
    "                 stop={\"training_iteration\": 3 },\n",
    "                 resources_per_trial={\"gpu\": 0.5},\n",
    "                 local_dir='/mnt/data/ray_results')#no cpu count is necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No `mode` has been passed and  `default_mode` has not been set. Please specify the `mode` parameter.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-db950a0b59dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhp_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-885d98ed8cb8>\u001b[0m in \u001b[0;36mbest_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalysis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_lrn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmut_conf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mf_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/ray/tune/analysis/experiment_analysis.py\u001b[0m in \u001b[0;36mget_best_trial\u001b[0;34m(self, metric, mode, scope)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \"\"\"\n\u001b[1;32m    498\u001b[0m         \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscope\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"all\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"last\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"avg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"last-5-avg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"last-10-avg\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/ray/tune/analysis/experiment_analysis.py\u001b[0m in \u001b[0;36m_validate_mode\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             raise ValueError(\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0;34m\"No `mode` has been passed and  `default_mode` has \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                 \"not been set. Please specify the `mode` parameter.\")\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"min\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"max\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No `mode` has been passed and  `default_mode` has not been set. Please specify the `mode` parameter."
     ]
    }
   ],
   "source": [
    "hp_opt.best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lrn(dls,config):\n",
    "    lrn = RNNLearner(dls,hidden_size=config['hidden_size'],metrics=[fun_rmse,mse])\n",
    "    return lrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomReporter(Callback):\n",
    "    \"`Callback` reports progress after every epoch to the ray tune logger\"\n",
    "\n",
    "    def after_epoch(self):\n",
    "        train_loss,valid_loss,rmse,mse = self.learn.recorder.values[-1]\n",
    "        tune.report(train_loss=train_loss,\n",
    "                        valid_loss=valid_loss,\n",
    "                        mean_loss=rmse,\n",
    "                        mse=mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_opt = HPOptimizer(create_lrn,dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-04 00:46:42,948\tINFO services.py:1166 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "hp_opt.start_ray(local_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"hidden_size\": tune.grid_search([10,20,50,100]),\n",
    "    'n_epoch':20,\n",
    "    'reporter':ray.put(CustomReporter)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 15.8/125.8 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 4/64 CPUs, 2.0/2 GPUs, 0.0/75.78 GiB heap, 0.0/25.15 GiB objects (0/1.0 accelerator_type:RTX)<br>Result logdir: /home/daniel/ray_results/learner_optimize<br>Number of trials: 4 (4 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                  </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  valid_loss</th><th style=\"text-align: right;\">      mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>learner_optimize_50b24_00000</td><td>RUNNING </td><td>130.149.48.236:58877</td><td style=\"text-align: right;\">           10</td><td style=\"text-align: right;\">0.263788</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         10.8797</td><td style=\"text-align: right;\">   0.0728292</td><td style=\"text-align: right;\">   0.0696044</td><td style=\"text-align: right;\">0.0696044</td></tr>\n",
       "<tr><td>learner_optimize_50b24_00001</td><td>RUNNING </td><td>130.149.48.236:58886</td><td style=\"text-align: right;\">           20</td><td style=\"text-align: right;\">0.246422</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         10.8895</td><td style=\"text-align: right;\">   0.0563075</td><td style=\"text-align: right;\">   0.060776 </td><td style=\"text-align: right;\">0.060776 </td></tr>\n",
       "<tr><td>learner_optimize_50b24_00002</td><td>RUNNING </td><td>130.149.48.236:58865</td><td style=\"text-align: right;\">           50</td><td style=\"text-align: right;\">0.247049</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         10.0826</td><td style=\"text-align: right;\">   0.0629461</td><td style=\"text-align: right;\">   0.0610912</td><td style=\"text-align: right;\">0.0610912</td></tr>\n",
       "<tr><td>learner_optimize_50b24_00003</td><td>RUNNING </td><td>130.149.48.236:58843</td><td style=\"text-align: right;\">          100</td><td style=\"text-align: right;\">0.24187 </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         11.9689</td><td style=\"text-align: right;\">   0.0554109</td><td style=\"text-align: right;\">   0.0585442</td><td style=\"text-align: right;\">0.0585442</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=58865)\u001b[0m (#6) [2,0.06042690947651863,0.062047552317380905,0.24902784824371338,0.062047552317380905,'00:02']\n",
      "\u001b[2m\u001b[36m(pid=58877)\u001b[0m (#6) [3,0.06832592189311981,0.06365511566400528,0.25223809480667114,0.06365511566400528,'00:02']\n",
      "\u001b[2m\u001b[36m(pid=58886)\u001b[0m (#6) [2,0.05600298196077347,0.06078524515032768,0.24643062055110931,0.06078524515032768,'00:02']\n",
      "\u001b[2m\u001b[36m(pid=58843)\u001b[0m (#6) [3,0.0529298298060894,0.04839551821351051,0.21991665661334991,0.04839551821351051,'00:02']\n",
      "\u001b[2m\u001b[36m(pid=58877)\u001b[0m (#6) [4,0.06469633430242538,0.061240993440151215,0.24737101793289185,0.061240993440151215,'00:02']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2612b345a3ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m hp_opt.optimize(resources_per_trial={\"gpu\": 0.5},\n\u001b[0;32m----> 2\u001b[0;31m                 config=search_space)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-885d98ed8cb8>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, config, optimize_func, resources_per_trial, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mresources_per_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresources_per_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, loggers, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_report_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_running_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_no_available_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;31m# TODO(ujvl): Consider combining get_next_available_trial and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;31m#  fetch_result functionality so that we don't timeout on fetch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_available_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_restoring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mwarn_if_slow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"process_trial_restore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_available_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;31m# See https://github.com/ray-project/ray/issues/4211 for details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mresult_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m         \u001b[0mwait_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait_time\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mNONTRIVIAL_WAIT_TIME_THRESHOLD_S\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_refs, num_returns, timeout)\u001b[0m\n\u001b[1;32m   1556\u001b[0m             \u001b[0mnum_returns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m             \u001b[0mtimeout_milliseconds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1558\u001b[0;31m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1559\u001b[0m         )\n\u001b[1;32m   1560\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mready_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=58865)\u001b[0m (#6) [3,0.05882358178496361,0.060489363968372345,0.24586324393749237,0.060489363968372345,'00:02']\n",
      "\u001b[2m\u001b[36m(pid=58886)\u001b[0m (#6) [3,0.05570889264345169,0.060445960611104965,0.24575257301330566,0.060445960611104965,'00:02']\n",
      "\u001b[2m\u001b[36m(pid=58843)\u001b[0m (#6) [4,0.04667248576879501,0.02904750406742096,0.1703760176897049,0.02904750406742096,'00:02']\n"
     ]
    }
   ],
   "source": [
    "hp_opt.optimize(resources_per_trial={\"gpu\": 0.5},\n",
    "                config=search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_opt.analysis.get_best_config('mean_loss',mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
