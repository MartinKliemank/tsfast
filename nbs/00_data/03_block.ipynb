{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Corefunctionality for data preparation of sequential data for pytorch,\n",
    "  fastai models\n",
    "output-file: core.html\n",
    "title: Corefunctions\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data.block\n",
    "#| default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastai.data.all import *\n",
    "from fastai.vision.augment import RandTransform\n",
    "from tsfast.data.core import *\n",
    "from tsfast.data.transforms import *\n",
    "from tsfast.data.split import *\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataloaders Creation\n",
    "A Datasets combines all implemented components on item level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def pad_sequence(batch,sorting = False):\n",
    "    '''collate_fn for padding of sequences of different lengths, use in before_batch of databunch, still quite slow'''\n",
    "    #takes list of tuples as input, returns list of tuples\n",
    "    sorted_batch = sorted(batch, key=lambda x: x[0].shape[0], reverse=True) if sorting else batch\n",
    "\n",
    "    pad_func = partial(torch.nn.utils.rnn.pad_sequence,batch_first=True)\n",
    "    padded_tensors = [pad_func([x[tup] for x in sorted_batch]) for tup in range(len(batch[0]))]\n",
    "    padded_list = [retain_types(tuple([tup[entry] for tup in padded_tensors]),batch[0]) for entry in range(len(batch))]\n",
    "    #retain types is important for decoding later back to source items\n",
    "#     import pdb; pdb.set_trace()\n",
    "    \n",
    "    return padded_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Low-Level with Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.config import get_config\n",
    "from tsfast.data.core import CreateDict, ValidClmContains,DfHDFCreateWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = get_config().config_file.parent\n",
    "f_path = project_root / 'test_data/WienerHammerstein'\n",
    "hdf_files = get_files(f_path,extensions='.hdf5',recurse=True)\n",
    "tfm_src = CreateDict([ValidClmContains(['valid']),DfHDFCreateWindows(win_sz=100+1,stp_sz=10,clm='u')])\n",
    "src_dicts = tfm_src(hdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm_src = CreateDict([ValidClmContains(['valid']),DfHDFCreateWindows(win_sz=100+1,stp_sz=10,clm='u')])\n",
    "src_dicts = tfm_src(hdf_files)\n",
    "\n",
    "tfms=[  [HDF2Sequence(['u','y']),SeqSlice(l_slc=1),toTensorSequencesInput],\n",
    "        [HDF2Sequence(['y']),SeqSlice(r_slc=-1),toTensorSequencesOutput]]\n",
    "splits = PercentageSplitter()([x['path'] for x in src_dicts])\n",
    "dsrc = Datasets(src_dicts,tfms=tfms,splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# dsrc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 100, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = dsrc.dataloaders(bs=128,after_batch=[SeqNoiseInjection(std=[1.1,0.01]),Normalize(axes=[0,1])],before_batch=pad_sequence)\n",
    "db.one_batch()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Mid-Level with Datablock API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SequenceBlock(TransformBlock):\n",
    "    def __init__(self, seq_extract,padding=False):\n",
    "        return super().__init__(type_tfms=[seq_extract],\n",
    "                                batch_tfms=[Normalize(axes=[0,1])],\n",
    "                                dls_kwargs={} if not padding else {'before_batch': pad_sequence})\n",
    "\n",
    "    @classmethod\n",
    "    @delegates(HDF2Sequence, keep=True)\n",
    "    def from_hdf(cls, clm_names, seq_cls=TensorSequencesInput,padding=False, **kwargs):\n",
    "        return cls(HDF2Sequence(clm_names,to_cls=seq_cls,**kwargs), padding)\n",
    "\n",
    "    @classmethod\n",
    "    def from_numpy(cls, seq_cls=TensorSequencesInput,padding=False, **kwargs):\n",
    "        return cls(ToTensor(enc=seq_cls), padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = DataBlock(blocks=(SequenceBlock.from_hdf(['u','y'],TensorSequencesInput,padding=True,cached=None),\n",
    "                        SequenceBlock.from_hdf(['y'],TensorSequencesOutput,cached=None)),\n",
    "                get_items=tfm_src,\n",
    "                splitter=ApplyToDict(ParentSplitter()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = seq.dataloaders(hdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ScalarNormalize(DisplayedTransform):\n",
    "    def __init__(self, mean=None, std=None, axes=(0,)): store_attr()\n",
    "        \n",
    "    @classmethod\n",
    "    def from_stats(cls, mean, std, dim=1, ndim=4, cuda=True): return cls(*broadcast_vec(dim, ndim, mean, std, cuda=cuda))\n",
    "    \n",
    "    def setups(self, dl:DataLoader):\n",
    "        if self.mean is None or self.std is None:\n",
    "            b = dl.one_batch()\n",
    "            for x in b:\n",
    "                if isinstance(x,TensorScalarsInput):\n",
    "                    self.mean,self.std = x.mean(self.axes, keepdim=True),x.std(self.axes, keepdim=True)+1e-7\n",
    "                    return\n",
    "\n",
    "    def encodes(self, x:TensorScalarsInput): \n",
    "        if x.device != self.mean.device:\n",
    "            self.mean = self.mean.to(x.device)\n",
    "            self.std = self.std.to(x.device)\n",
    "        return (x-self.mean) / self.std\n",
    "    \n",
    "    def decodes(self, x:TensorScalarsInput):\n",
    "        if x.device != self.mean.device:\n",
    "            self.mean = self.mean.to(x.device)\n",
    "            self.std = self.std.to(x.device)\n",
    "        return (x*self.std + self.mean)\n",
    "\n",
    "class ScalarBlock(TransformBlock):\n",
    "    def __init__(self, scl_extract):\n",
    "        return super().__init__(type_tfms=[scl_extract],\n",
    "                                batch_tfms=[ScalarNormalize()])\n",
    "\n",
    "    @classmethod\n",
    "    @delegates(HDF2Scalars, keep=True)\n",
    "    def from_hdf(cls, clm_names, scl_cls=TensorScalarsInput, **kwargs):\n",
    "        return cls(HDF2Scalars(clm_names,to_cls=scl_cls,**kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Spectrogram-Datablock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TensorSpectrogram(TensorBase):\n",
    "    def show(self, ctx=None, ax=None, title=\"\", **kwargs):\n",
    "        ax = ifnone(ax, ctx)\n",
    "        if ax is None:\n",
    "            _, ax = plt.subplots()\n",
    "        ax.axis(False)\n",
    "        n_channels = self.shape[0]\n",
    "        for i, channel in enumerate(self):\n",
    "            ia = ax.inset_axes((i / n_channels, 0.2, 1 / n_channels, 0.7))\n",
    "#             ia = ax.inset_axes((i / n_channels, 0, 1 / n_channels, 1))\n",
    "    \n",
    "            ia.imshow(channel.cpu().numpy(),aspect ='auto',origin ='lower')\n",
    "            if i>0: ia.set_yticks([])\n",
    "            ia.set_title(f\"Channel {i}\")\n",
    "        ax.set_title(title)\n",
    "        return ax\n",
    "\n",
    "class TensorSpectrogramInput(TensorSpectrogram): pass\n",
    "class TensorSpectrogramOutput(TensorSpectrogram): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_spec = TensorSpectrogramInput(HDF2Sequence(['u'],to_cls=TensorSpectrogramInput)._hdf_extract_sequence(hdf_files[0],r_slc=2000))\n",
    "seq_spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def complex_norm(\n",
    "        complex_tensor: Tensor,\n",
    "        power: float = 1.0\n",
    ") -> Tensor:\n",
    "    if power == 1.0:\n",
    "        return torch.norm(complex_tensor, 2, -1)\n",
    "    return torch.norm(complex_tensor, 2, -1).pow(power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def spectrogram(\n",
    "        waveform: Tensor,\n",
    "        pad: int,\n",
    "        window: Tensor,\n",
    "        n_fft: int,\n",
    "        hop_length: int,\n",
    "        win_length: int,\n",
    "        power: Optional[float],\n",
    "        normalized: bool\n",
    ") -> Tensor:\n",
    "    if pad > 0:\n",
    "        waveform = torch.nn.functional.pad(waveform, (pad, pad), \"constant\")\n",
    "\n",
    "    # pack batch\n",
    "    shape = waveform.size()\n",
    "    waveform = waveform.view(-1, shape[-1])\n",
    "\n",
    "    # default values are consistent with librosa.core.spectrum._spectrogram\n",
    "    spec_f = torch.view_as_real(torch.stft(\n",
    "        waveform, n_fft, hop_length, win_length, window, True, \"reflect\", False, True,return_complex=True\n",
    "    ))\n",
    "\n",
    "    # unpack batch\n",
    "    spec_f = spec_f.view(shape[:-1] + spec_f.shape[-3:])\n",
    "\n",
    "    if normalized:\n",
    "        spec_f /= window.pow(2.).sum().sqrt()\n",
    "    if power is not None:\n",
    "        spec_f = complex_norm(spec_f, power=power)\n",
    "\n",
    "    return spec_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "from typing import Callable\n",
    "\n",
    "class Spectrogram(torch.nn.Module):\n",
    "    r\"\"\"Create a spectrogram from a audio signal.\n",
    "\n",
    "    Args:\n",
    "        n_fft (int, optional): Size of FFT, creates ``n_fft // 2 + 1`` bins. (Default: ``400``)\n",
    "        win_length (int or None, optional): Window size. (Default: ``n_fft``)\n",
    "        hop_length (int or None, optional): Length of hop between STFT windows. (Default: ``win_length // 2``)\n",
    "        pad (int, optional): Two sided padding of signal. (Default: ``0``)\n",
    "        window_fn (Callable[..., Tensor], optional): A function to create a window tensor\n",
    "            that is applied/multiplied to each frame/window. (Default: ``torch.hann_window``)\n",
    "        power (float or None, optional): Exponent for the magnitude spectrogram,\n",
    "            (must be > 0) e.g., 1 for energy, 2 for power, etc.\n",
    "            If None, then the complex spectrum is returned instead. (Default: ``2``)\n",
    "        normalized (bool, optional): Whether to normalize by magnitude after stft. (Default: ``False``)\n",
    "        wkwargs (dict or None, optional): Arguments for window function. (Default: ``None``)\n",
    "    \"\"\"\n",
    "    __constants__ = ['n_fft', 'win_length', 'hop_length', 'pad', 'power', 'normalized']\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_fft: int = 400,\n",
    "                 win_length: Optional[int] = None,\n",
    "                 hop_length: Optional[int] = None,\n",
    "                 pad: int = 0,\n",
    "                 window_fn: Callable[..., Tensor] = torch.hann_window,\n",
    "                 power: Optional[float] = 2.,\n",
    "                 normalized: bool = False,\n",
    "                 wkwargs: Optional[dict] = None) -> None:\n",
    "        super(Spectrogram, self).__init__()\n",
    "        self.n_fft = n_fft\n",
    "        # number of FFT bins. the returned STFT result will have n_fft // 2 + 1\n",
    "        # number of frequecies due to onesided=True in torch.stft\n",
    "        self.win_length = win_length if win_length is not None else n_fft\n",
    "        self.hop_length = hop_length if hop_length is not None else self.win_length // 2\n",
    "        window = window_fn(self.win_length) if wkwargs is None else window_fn(self.win_length, **wkwargs)\n",
    "        self.register_buffer('window', window)\n",
    "        self.pad = pad\n",
    "        self.power = power\n",
    "        self.normalized = normalized\n",
    "\n",
    "    def forward(self, waveform: Tensor) -> Tensor:\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            waveform (Tensor): Tensor of audio of dimension (..., time).\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Dimension (..., freq, time), where freq is\n",
    "            ``n_fft // 2 + 1`` where ``n_fft`` is the number of\n",
    "            Fourier bins, and time is the number of window hops (n_frame).\n",
    "        \"\"\"\n",
    "        return spectrogram(waveform, self.pad, self.window, self.n_fft, self.hop_length,\n",
    "                             self.win_length, self.power, self.normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@delegates(Spectrogram, keep=True)\n",
    "class Sequence2Spectrogram(Transform):\n",
    "    '''calculates the FFT of a sequence'''\n",
    "    \n",
    "    def __init__(self,scaling='log',**kwargs): \n",
    "        self.scaling=scaling\n",
    "        self.tfm = Spectrogram(**kwargs)\n",
    "        \n",
    "    def encodes(self, o:TensorSpectrogram): \n",
    "        if o.device != self.tfm.window.device: self.tfm.window = self.tfm.window.to(o.device)\n",
    "#         import pdb;pdb.set_trace()\n",
    "        spec = self.tfm(o.transpose(-1,-2).contiguous())\n",
    "        if self.scaling == 'log': spec = torch.log10(spec + 1e-10)\n",
    "        return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SpectrogramBlock(TransformBlock):\n",
    "    def __init__(self, seq_extract,padding=False,n_fft=100,hop_length=None,normalized=False):\n",
    "        return super().__init__(type_tfms=[seq_extract],\n",
    "                                batch_tfms=[Sequence2Spectrogram(n_fft=n_fft,hop_length=hop_length,normalized=normalized)],\n",
    "                                dls_kwargs={} if not padding else {'before_batch': pad_sequence})\n",
    "\n",
    "    @classmethod\n",
    "    @delegates(HDF2Sequence, keep=True)\n",
    "    def from_hdf(cls, clm_names, seq_cls=TensorSpectrogramInput,padding=False,n_fft=100,hop_length=None,normalized=False, **kwargs):\n",
    "        return cls(HDF2Sequence(clm_names,to_cls=seq_cls,**kwargs), padding,n_fft=n_fft,hop_length=hop_length,normalized=normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_spec = DataBlock(blocks=(SpectrogramBlock.from_hdf(['u','y'],n_fft=100,hop_length=10,normalized=True),\n",
    "                        SequenceBlock.from_hdf(['y'],TensorSequencesOutput)),\n",
    "                get_items= CreateDict([DfHDFCreateWindows(win_sz=2000+1,stp_sz=10,clm='u')]),\n",
    "                splitter=ApplyToDict(ParentSplitter())).dataloaders(hdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2, 51, 201])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls_spec.one_batch()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
