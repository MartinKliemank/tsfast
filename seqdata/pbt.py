#AUTOGENERATED! DO NOT EDIT! File to edit: dev/13_PBT.ipynb (unless otherwise specified).

__all__ = ['rgetattr', 'rsetattr', 'log_uniform', 'HyperParamManager', 'obj_in_lst', 'LearnerTrainable', 'PBTOpt']

#Cell
from .core import *
from .model import *
from .learner import *
from fastai2.basics import *
from fastai2.callback.schedule import *
from fastai2.callback.rnn import *
from fastai2.callback.tracker import *

import ray
from ray import tune
from ray.tune import Trainable
from ray.tune.schedulers import PopulationBasedTraining
from ray.tune.trial import ExportFormat

#Cell
def rgetattr(obj, attr, *args):
    def _getattr(obj, attr):
        return getattr(obj, attr, *args)
    return functools.reduce(_getattr, [obj] + attr.split('.'))

def rsetattr(obj, attr, val):
    pre, _, post = attr.rpartition('.')
    return setattr(rgetattr(obj, pre) if pre else obj, post, val)

#Cell
def log_uniform(min_bound, max_bound, base=10):
    '''uniform sampling in an exponential range'''
    logmin = np.log(min_bound) / np.log(base)
    logmax = np.log(max_bound) / np.log(base)
    def _sample():
        return base**(np.random.uniform(logmin, logmax))
    return _sample

#Cell
class HyperParamManager():
    def __init__(self):
        self.params = {}

    def add_hyperparam(self,hp_owner:object, hp_name:str, hp_attr:str=None ):
        if hp_attr is None: hp_attr = hp_name
        if not hasattr(hp_owner,hp_attr): raise AttributeError()
        self.params[hp_name] = (hp_owner,hp_attr)

    def rm_hyperparam(self,hp_name:str):
        if hp_name in self.params:
            del self.params[hp_name]

    def set_hyperparams(self,config):
        for key in config:
            if key in self.params:
                hp_owner,hp_attr = self.params[key]
                setattr(hp_owner,hp_attr,config[key])

#Cell
def obj_in_lst(lst,cls):
    '''retrieve first object of type cls from a list'''
    return next(o for o in lst if type(o) is cls)

#Cell
class LearnerTrainable(tune.Trainable):

    def _setup(self, config):
        self.lrn = config['create_lrn']()
        self.lrn.hpm.set_hyperparams(config)

    def _train(self):
        with self.lrn.no_bar(): self.lrn.fit(1,lr=self.config["lr"])
        rmse = self.lrn.recorder.values[-1][-1]
        return {"mean_loss": rmse}

    def _save(self, checkpoint_dir):
        checkpoint_path = os.path.join(checkpoint_dir, "model.pth")
        torch.save(self.lrn.model.state_dict(), checkpoint_path)
        return checkpoint_path

    def _restore(self, checkpoint_path):
        self.lrn.model.load_state_dict(torch.load(checkpoint_path))

    def _export_model(self, export_formats, export_dir):
        if export_formats == [ExportFormat.MODEL]:
            path = os.path.join(export_dir, "exported_model")
            torch.save(self.lrn.model.state_dict(), path)
            return {ExportFormat.MODEL: path}
        else:
            raise ValueError("unexpected formats: " + str(export_formats))

    def reset_config(self, new_config):
        self.lrn.hpm.set_hyperparams(new_config)
        self.config = new_config
        return True

#Cell
class PBTOpt():
    def __init__(self,create_lrn):
        self.create_lrn = create_lrn

    @delegates(ray.init)
    def start_ray(self,**kwargs):
        ray.shutdown()
        ray.init(**kwargs)

    def stop_ray(self):
        ray.shutdown()

    @delegates(tune.run, keep=True)
    def optimize(self,opt_name,num_samples,config,mut_conf,freq=2,
                 stop={"training_iteration": 40 },
                 resources_per_trial={"gpu": 1 },
                 **kwargs):

        config['create_lrn'] = self.create_lrn

        scheduler = PopulationBasedTraining(
        time_attr="training_iteration",
        metric="mean_loss",
        mode="min",
        perturbation_interval=freq,
        hyperparam_mutations=mut_conf)

        self.analysis = tune.run(
            LearnerTrainable,
            name=opt_name,
            scheduler=scheduler,
            reuse_actors=True,
            verbose=1,
            stop=stop,
            checkpoint_score_attr="mean_loss",
            checkpoint_freq=freq,
            keep_checkpoints_num=4,
            num_samples=num_samples,
            resources_per_trial=resources_per_trial,
            config=config,
            **kwargs)
        return self.analysis

    def best_model(self):
        if self.analysis is None: raise Exception
        model = self.create_lrn().model
        f_path = self.analysis.get_best_trial('mean_loss').checkpoint.value
        model.load_state_dict(torch.load(f_path))
        return model