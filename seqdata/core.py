#AUTOGENERATED! DO NOT EDIT! File to edit: dev/00_core.ipynb (unless otherwise specified).

__all__ = ['get_hdf_files', 'hdf_extensions', 'df_source_items', 'DfHDFCreateWindows', 'TensorSequences',
           'TensorSequencesInput', 'TensorSequencesOutput', 'toTensorSequencesInput', 'toTensorSequencesOutput',
           'TensorScalars', 'TensorScalarsInput', 'TensorScalarsOutput', 'HDF2Sequence', 'hdf2scalars', 'SequenceItem',
           'SeqTfm', 'SeqSlice', 'SeqNoiseInjection', 'ParentSplitter']

#Cell
from fastai2.data.all import *
import h5py

#Cell
hdf_extensions = ['.hdf5']
def get_hdf_files(path,recurse=True, folders=None):
    "Get hdf5 files in `path` recursively, only in `folders`, if specified."
    return get_files(path, extensions=hdf_extensions, recurse=recurse, folders=folders)

#Cell
def df_source_items(f_list,pd_tfms = None):
    '''Create Pandas Dataframe out of a list of items, with a list of df transforms applied'''
    df = pd.DataFrame(data=f_list.items,columns=['path'])
    if pd_tfms is not None:
        for t in pd_tfms:
            df = t(df)
    return df

#Cell
def DfHDFCreateWindows(win_sz,stp_sz, clm, fixed_start = False, fixed_end = False):
    '''create windows of sequences, splits sequence into multiple items'''
    def _inner(df):
        if fixed_start and fixed_end: raise Exception

        lst_df = [] #new dataframe for every row
        for idx, row in df.iterrows():
            with h5py.File(row.path,'r') as f:
                #TODO make clm optional
#                 if clm == '':
#                     clm = list(f.keys())[0]
                f_len = f[clm].shape[0]

                n_win = ((f_len-win_sz)//stp_sz)+1
                tmp_df = df.iloc[[idx]*n_win]; #duplicate the row of the df multiple times by reference
                lst_idx = np.arange(n_win)

                #every row is a reference so we need to suppress the warning messages while copying
                pd.options.mode.chained_assignment = None
                tmp_df['l_slc'] = lst_idx*stp_sz
                tmp_df['r_slc'] = lst_idx*stp_sz + win_sz
                pd.options.mode.chained_assignment = 'warn'

                lst_df.append(tmp_df)

        res_df = pd.concat(lst_df)
        return res_df

    return _inner

#Cell
class TensorSequences(TensorBase): pass
class TensorSequencesInput(TensorSequences): pass
class TensorSequencesOutput(TensorSequences): pass

#Cell
@Transform
def toTensorSequencesInput(o): return TensorSequencesInput(o)
@Transform
def toTensorSequencesOutput(o): return TensorSequencesOutput(o)

#Cell
class TensorScalars(TensorBase): pass
class TensorScalarsInput(TensorScalars): pass
class TensorScalarsOutput(TensorScalars): pass

#Cell
from functools import lru_cache

def HDF2Sequence(c_names,cached=True):
    def _extract_sequence(hdf_path,dataset = None, l_slc = None, r_slc= None):
        with h5py.File(hdf_path,'r') as f:
            ds = f if dataset is None else f[dataset]
            l_array = [ds[n][l_slc:r_slc][:,None] for n in c_names]
            seq = np.concatenate(l_array,axis=1)
            return tensor(seq)

    _exseq = lru_cache(maxsize=None)(_extract_sequence) if cached else _extract_sequence

    def _extract_df_sequence(item):
        if not isinstance(item,pd.Series):
            return _exseq(str(item))

        path = item.path
        dataset = item.dataset if hasattr(item,'dataset') else None
        l_slc = item.l_slc if hasattr(item,'l_slc') else None
        r_slc = item.r_slc if hasattr(item,'r_slc') else None

        if cached:
            return _exseq(path,dataset)[l_slc:r_slc]
        else:
            return _exseq(path,dataset,l_slc,r_slc)

    return _extract_df_sequence

#Cell
def hdf2scalars(hdf_path,c_names):
    with h5py.File(hdf_path,'r') as f:
#         import pdb; pdb.set_trace()
#         l_array = [f[n][:][:,None] for n in c_names]
#         seq = np.concatenate(l_array,axis=1)
        return None

#Cell

#TODO: Fallunterscheidung der Sequenzen
class SequenceItem(Tuple):
    def show(self, ctx=None, **kwargs):
        plt.figure()
        plt.plot(self[2])

#Cell
class SeqTfm(Transform):
    def decodes(self, x): return SequenceItem(x)

#Cell
class SeqSlice(Transform):
    '''Take a slice from an array-like object. Useful for e.g. shifting input and output'''
    def __init__(self, l_slc=None,r_slc=None):
        self.l_slc,self.r_slc = l_slc,r_slc

    def encodes(self, o): return o[self.l_slc:self.r_slc]

#Cell
class SeqNoiseInjection(Transform):
    '''Adds normal distributed noise to the tensor sequence with seperate mean and std for every signal'''
    def __init__(self, std=1e-1,mean=0.):
        self.std,self.mean = tensor(std),tensor(mean)

    def setups(self, dl:DataLoader):
        #check the tensor type of your input
        #TODO: include scalar type case
        x,*_ = dl.one_batch()
        self.std = to_device(self.std,x.device)
        self.mean = to_device(self.mean,x.device)

    def encodes(self, o:TensorSequencesInput):
        #expand creates a view on a tensor and is therefore very fast compared to copy
        return o+torch.normal(mean=self.mean.expand_as(o),
                              std=self.std.expand_as(o))

#     def decodes(self, o): return o-self.mean

#Cell
def _parent_idxs(items, name): return mask2idxs(Path(o).parent.name == name for o in items)

def ParentSplitter(train_name='train', valid_name='valid'):
    "Split `items` from the parent folder names (`train_name` and `valid_name`)."
    def _inner(o, **kwargs):
        return _parent_idxs(o, train_name),_parent_idxs(o, valid_name)
    return _inner