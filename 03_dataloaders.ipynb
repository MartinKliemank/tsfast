{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dataloaders\n",
    "# default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%matplotlib widget\n",
    "from fastai2.callback.progress import *\n",
    "from fastai2.callback.tracker import *\n",
    "from fastai2.callback.schedule import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from seqdata.core import *\n",
    "from seqdata.model import *\n",
    "from seqdata.learner import *\n",
    "from fastai2.basics import *\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataloaders\n",
    "> Pytorch Modules for Training Models for sequential data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncated Backpropagation Through Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tbptt dataloader needs to split the minibatches that are created in several smaller minibatches that will be returned sequentially before the next minibatch may be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data.dataloader import _MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter,_DatasetKind\n",
    "_loaders = (_MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter)\n",
    "@delegates()\n",
    "class TbpttDl(TfmdDL):\n",
    "\n",
    "    def __init__(self, dataset, sub_seq_len=None,max_batches=None, seq_len = None ,shuffle=True,num_workers=0, **kwargs):\n",
    "#         assert sub_seq_len is not None\n",
    "        store_attr(self,'sub_seq_len,max_batches,seq_len')\n",
    "        super().__init__(dataset=dataset, shuffle=shuffle, num_workers=num_workers, **kwargs)\n",
    "        self.rnn_reset = False\n",
    "    @property\n",
    "    def n_sub_seq(self):\n",
    "        if self.sub_seq_len is None: return 1\n",
    "        if self.seq_len is None: self.seq_len = self.do_item(0)[0].shape[0]\n",
    "        return math.ceil(self.seq_len / self.sub_seq_len)\n",
    "        \n",
    "    def __len__(self):\n",
    "        l = super().__len__() * self.n_sub_seq\n",
    "        if self.max_batches is not None: l = min(l,self.max_batches)\n",
    "        return l\n",
    "    \n",
    "    def _next_worker(self,w_id):\n",
    "        w_id += 1\n",
    "        if w_id > self.fake_l.num_workers-1: w_id = 0\n",
    "        return w_id\n",
    "    \n",
    "    def __iter__(self):\n",
    "        '''iterator that handles multiprocessing by caching samples that are generated out of order'''\n",
    "        self.randomize()\n",
    "        self.before_iter()\n",
    "        n_buffer = self.fake_l.num_workers*self.n_sub_seq\n",
    "        queue = {n:[] for n in range(self.fake_l.num_workers)} \n",
    "        current_worker = None\n",
    "        idx = 0\n",
    "        for loaded_b,w_id in _loaders[self.fake_l.num_workers==0](self.fake_l):\n",
    "            if self.max_batches is not None and idx >= self.max_batches: break #check if batch limit has been reached\n",
    "#             import pdb; pdb.set_trace()\n",
    "            if w_id is None:\n",
    "                self.rnn_reset=True\n",
    "                b= loaded_b\n",
    "                self.rnn_reset = (idx % self.n_sub_seq) == 0\n",
    "                yield self.after_batch(b if self.device is None else to_device(b, self.device))\n",
    "                idx += 1 #idx increments after every yield, not every loop\n",
    "            else:\n",
    "                if current_worker is None:\n",
    "                    current_worker = w_id\n",
    "                \n",
    "                #retrieve queued elements from worker\n",
    "                while len(queue[current_worker]) > 0:\n",
    "                    b = queue[current_worker].pop(0)\n",
    "                    self.rnn_reset = (idx % self.n_sub_seq) == 0\n",
    "                    yield self.after_batch(b if self.device is None else to_device(b, self.device))\n",
    "                    idx += 1\n",
    "                    if (idx % self.n_sub_seq) == 0:\n",
    "                        current_worker = self._next_worker(current_worker) #next worker, stay in loop for the queue\n",
    "                        \n",
    "                \n",
    "                #retrieve fresh elements from worker\n",
    "                if w_id != current_worker: #not active worker\n",
    "                    queue[w_id] += [loaded_b]\n",
    "                    continue\n",
    "                else:#active worker\n",
    "                    b = loaded_b\n",
    "                    self.rnn_reset = (idx % self.n_sub_seq) == 0\n",
    "                    yield self.after_batch(b if self.device is None else to_device(b, self.device))\n",
    "                    idx += 1 #idx increments after every yield, not every loop\n",
    "                    if (idx % self.n_sub_seq) == 0:\n",
    "                        current_worker = self._next_worker(current_worker)\n",
    "                \n",
    "        self.after_iter()\n",
    "        if hasattr(self, 'it'): delattr(self, 'it')\n",
    "    \n",
    "    def create_batches(self, samps):\n",
    "        yield from self._tbptt_generator(super().create_batches(samps))\n",
    "        \n",
    "    def _tbptt_generator(self,batch_iter):\n",
    "        '''generator function that splits batches in smaller windows and truncates batch count if max_batches is set, yields mini_batch and worker id'''\n",
    "        for idx,b in enumerate(batch_iter):\n",
    "            for i in range(self.n_sub_seq):\n",
    "                #it is importan to retain the tuple type, or future transforms may now work\n",
    "                if self.sub_seq_len is None:\n",
    "                    trunc_b = b\n",
    "                else:\n",
    "                    trunc_b = tuple([retain_type(x[:,i*self.sub_seq_len:(i+1)*self.sub_seq_len],x) for x in b])\n",
    "                yield trunc_b, (None if torch.utils.data.get_worker_info() is None else torch.utils.data.get_worker_info().id)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm_lst = [DfHDFCreateWindows(win_sz=1000+1,stp_sz=1000,clm='current')]\n",
    "seq = DataBlock(blocks=(SequenceBlock.from_hdf(['current','voltage'],TensorSequencesInput,clm_shift=[-1,-1]),\n",
    "                        SequenceBlock.from_hdf(['voltage'],TensorSequencesOutput,clm_shift=[1])),\n",
    "                 get_items=CreateDict(tfm_lst),\n",
    "                 splitter=ApplyToDict(ParentSplitter()))\n",
    "db = seq.dataloaders(get_hdf_files('test_data/'),dl_type=TbpttDl,sub_seq_len=100,max_batches=1000,num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [array(x[-1][0,:,0].cpu()) for x in db.train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/envs/fastaiv2/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92b25ac942247128c7efa7ca7f081d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f27f08f8210>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.concatenate(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_workers has to be 0. If there are parallel workers, the order of minibatches will be corrupted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TBPTT_Reset_Callback\n",
    "The stateful model needs to reset its hidden state, when a new sequence begins. The callback reads the reset flag and acts accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TbpttResetCB(Callback):\n",
    "    \"`Callback` resets the rnn model with every new sequence for tbptt\"\n",
    "        \n",
    "    def begin_batch(self):\n",
    "        dl = self.learn.dls.train if self.training else self.learn.dls.valid\n",
    "#         if not self.training: import pdb; pdb.set_trace()\n",
    "        if hasattr(dl,'rnn_reset')and dl.rnn_reset and hasattr(self.model,'reset'):\n",
    "            self.model.reset()\n",
    "        \n",
    "    def after_fit(self): \n",
    "        if hasattr(self.model,'reset'): self.model.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai2.learner.Learner at 0x7f27f083a210>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrn = RNNLearner(db,num_layers=1,rnn_type='gru',stateful=False,metrics=[SkipNLoss(fun_rmse,100)])\n",
    "lrn.add_cb(TbpttResetCB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fun_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.400621</td>\n",
       "      <td>0.016195</td>\n",
       "      <td>0.098020</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrn.fit_one_cycle(1,lr_max=3e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.train.max_batches = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.train.sub_seq_len = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fun_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.027535</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.016635</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrn.fit_one_cycle(1,lr_max=3e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Sampling Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A weighted sampling dataloader for nonuniforly distributed data. A factory method receives the base Dataloader class and returns the inherited weighted sampling dataloader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def WeightedDL_Factory(cls):\n",
    "    '''\n",
    "    Weighted Dataloader that provides control over sampling probabilities.\n",
    "    wgts: probability array with probability for every item\n",
    "            gets extracted from the pandas 'p_sample' column if given. \n",
    "            Otherwise uniform sampling will be enabled\n",
    "        \n",
    "    '''\n",
    "    assert issubclass(cls, TfmdDL)\n",
    "    \n",
    "    class WeightedDL(cls):\n",
    "        def __init__(self, dataset, wgts=None, **kwargs):\n",
    "#             import pdb;pdb.set_trace()\n",
    "            self.wgts = None\n",
    "            #self.items need to be assigned, but super.init needs wgts allready assigned\n",
    "            super().__init__(dataset=dataset, **kwargs) \n",
    "            if wgts is None:\n",
    "                if  (type(self.items) is list and\n",
    "                    type(self.items[0]) is dict and \n",
    "                    'p_sample' in self.items[0].keys()):\n",
    "                    self.wgts = np.array([x['p_sample'] for x in self.items])\n",
    "                    self.wgts = self.wgts/self.wgts.sum()\n",
    "                else:\n",
    "                    print('No wgts provided for WeightedDL. Was that intentional?')\n",
    "            else:\n",
    "                self.wgts = wgts/np.sum(wgts)\n",
    "\n",
    "        def get_idxs(self):\n",
    "            if self.n==0: return []\n",
    "            if not self.shuffle or self.wgts is None: return super().get_idxs()\n",
    "            return list(np.random.choice(self.n, self.n, p=self.wgts))\n",
    "    return WeightedDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = WeightedDL_Factory(TfmdDL)([1,2]*5,bs=10,wgts=[2,1]*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl.wgts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl.one_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ItemLst Transform for weight calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def uniform_p_of_category(cat_name):  \n",
    "    '''Scales sampling weights for an even distribution between every category'''\n",
    "    def _inner(df):\n",
    "        counts = df[cat_name].value_counts()\n",
    "        sample_prob =  1/counts\n",
    "        sample_prob.name = 'p_sample'\n",
    "        return df.merge(sample_prob,left_on=cat_name,right_index=True)\n",
    "    \n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid(df):   \n",
    "    ''' test function that extracts valid and train from the path string'''\n",
    "    df['train'] = df.path.astype(str).str.contains('train',regex=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm_lst = [train_valid, DfHDFCreateWindows(win_sz=1000+1,stp_sz=1000,clm='current') ,uniform_p_of_category('train')]\n",
    "apply_df_tfms(get_hdf_files('test_data/'),tfm_lst) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = DataBlock(blocks=(SequenceBlock.from_hdf(['current','voltage'],TensorSequencesInput,clm_shift=[-1,-1]),\n",
    "                        SequenceBlock.from_hdf(['voltage'],TensorSequencesOutput,clm_shift=[1])),\n",
    "                 get_items=CreateDict(tfm_lst),\n",
    "                 splitter=ApplyToDict(ParentSplitter()))\n",
    "db = seq.dataloaders(get_hdf_files('test_data/'),dl_type=WeightedDL_Factory(TbpttDl),sub_seq_len=10,max_batches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.train.wgts[:5],db.valid.wgts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_model.ipynb.\n",
      "Converted 02_learner.ipynb.\n",
      "Converted 03_dataloaders.ipynb.\n",
      "Converted 11_dualrnn.ipynb.\n",
      "Converted 12_TensorQuaternions.ipynb.\n",
      "Converted 13_HPOpt.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
