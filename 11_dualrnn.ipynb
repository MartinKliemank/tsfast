{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dualrnn\n",
    "# default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual RNN Models\n",
    "> Pytorch Models for Sequential Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from seqdata.core import *\n",
    "from seqdata.model import *\n",
    "from seqdata.learner import *\n",
    "from seqdata.dataloaders import *\n",
    "from fastai2.basics import *\n",
    "from fastai2.callback.progress import *\n",
    "from fastai2.callback.schedule import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_sz = 100\n",
    "seq = DataBlock(blocks=(SequenceBlock.from_hdf(['current','voltage'],TensorSequencesInput,clm_shift=[0,-1]),\n",
    "                        SequenceBlock.from_hdf(['voltage'],TensorSequencesOutput,clm_shift=[-1])),\n",
    "                 get_items=CreateDict([DfHDFCreateWindows(win_sz=20000+1,stp_sz=2000,clm='current')]),\n",
    "                 splitter=ApplyToDict(ParentSplitter()))\n",
    "dl_kwargs=[{'sub_seq_len':1000}]*2\n",
    "db = seq.dataloaders(get_hdf_files('test_data/'),bs=32,dl_type=TbpttDl,dl_kwargs=dl_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "db.show_batch(max_n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProDiag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ProDiagTrainer(Callback):\n",
    "    \"`Callback` that regroups lr adjustment to seq_len, AR and TAR.\"\n",
    "    def __init__(self, alpha=1e6,beta=1,p_own_state=0):\n",
    "        store_attr(self,'alpha,beta,p_own_state')\n",
    "        self.main_init_prop = None\n",
    "        \n",
    "    def _has_main_init(self):\n",
    "        return hasattr(self.learn.model,'main_init_prop')\n",
    "        \n",
    "    def begin_fit(self):\n",
    "        if self._has_main_init(): \n",
    "            self.main_init_prop=self.learn.model.main_init_prop\n",
    "            \n",
    "    def begin_batch(self):\n",
    "        if not self.training or self.p_own_state == 0: return\n",
    "        main_init_prop = random.random()< self.p_own_state\n",
    "        self.learn.model.main_init_prop = main_init_prop\n",
    "    \n",
    "    def after_pred(self):\n",
    "        p,self.pred_diag,self.est_hidden,self.pred_hidden=self.pred\n",
    "        self.learn.pred = p\n",
    "\n",
    "    def after_loss(self):\n",
    "        if not self.training: return\n",
    "        self.learn.loss = self.learn.loss+self.beta*self.learn.loss_func(self.pred_diag,*self.yb)\n",
    "        \n",
    "        hidden_loss = ((self.est_hidden-self.pred_hidden)/\n",
    "                       (self.est_hidden.norm()+self.pred_hidden.norm())).pow(2).mean()\n",
    "        self.learn.loss = self.learn.loss+self.alpha * hidden_loss\n",
    "        \n",
    "    def begin_validate(self):\n",
    "        '''Set Dual RNN to reuse the prediction state after each mini batch on validation'''\n",
    "        if self._has_main_init():\n",
    "            self.learn.model.main_init_prop = True\n",
    "        \n",
    "    def after_validate(self):\n",
    "        '''Reset Dual RNN to training state propagation behaviour'''\n",
    "        if self._has_main_init():\n",
    "            self.learn.model.main_init_prop=self.main_init_prop\n",
    "        \n",
    "        \n",
    "    def after_fit(self):\n",
    "        self.learn.model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DualRNN(nn.Module):\n",
    "    \n",
    "    @delegates(RNN, keep=True)\n",
    "    def __init__(self,main_input_size,co_input_size,output_size,init_sz=100,hidden_size=100,\n",
    "                 rnn_layer=1,linear_layer = 1,main_init_est = True,main_init_prop = True,**kwargs):\n",
    "        super().__init__()\n",
    "        store_attr(self,'main_input_size,co_input_size,main_init_est,main_init_prop,init_sz')\n",
    "        \n",
    "        rnn_kwargs = dict(hidden_size=hidden_size,num_layers=rnn_layer,stateful=True,ret_full_hidden=True)\n",
    "        rnn_kwargs = dict(rnn_kwargs, **kwargs)\n",
    "        \n",
    "        self.co_rnn = RNN(co_input_size,**rnn_kwargs) \n",
    "        self.main_rnn = RNN(main_input_size,**rnn_kwargs) \n",
    "\n",
    "#         self.co_estimator = SeqLinear(hidden_size,output_size,hidden_layer=linear_layer)\n",
    "        self.main_estimator = SeqLinear(hidden_size,output_size,hidden_layer=linear_layer)\n",
    "\n",
    "    def forward(self, x,init_state = None):\n",
    "        if init_state is None:\n",
    "            init_state = self.main_rnn.hidden if self.main_init_prop else self.co_rnn.hidden\n",
    "        \n",
    "        \n",
    "        x_co = x[...,:self.co_input_size]\n",
    "        x_main = x[...,:self.main_input_size]\n",
    "            \n",
    "        #RNN Layer \n",
    "        if init_state is None:\n",
    "#             import pdb; pdb.set_trace()\n",
    "            if self.main_init_est:\n",
    "                out_init,h_init = self.main_rnn(x_main[:,:self.init_sz])\n",
    "                out_main,_ = self.main_rnn(x_main[:,self.init_sz:],h_init)\n",
    "                out_co,_ = self.co_rnn(x_co[:,self.init_sz:],h_init)  \n",
    "                out_main=torch.cat([out_init,out_main],2) \n",
    "                out_co=torch.cat([out_init,out_co],2) \n",
    "            else:\n",
    "                out_init,h_init = self.co_rnn(x_co[:,:self.init_sz])\n",
    "                out_co,_ = self.co_rnn(x_co[:,self.init_sz:],h_init)\n",
    "                out_main,_ = self.main_rnn(x_main[:,self.init_sz:],h_init)  \n",
    "                out_main=torch.cat([out_init,out_main],2) \n",
    "                out_co=torch.cat([out_init,out_co],2) \n",
    "        else:  \n",
    "            out_co,_ = self.co_rnn(x_co,init_state)         \n",
    "            out_main,_ = self.main_rnn(x_main,init_state)\n",
    "            \n",
    "            \n",
    "#         import pdb; pdb.set_trace()\n",
    "            \n",
    "        #Shared Linear Layer\n",
    "        est_co = self.main_estimator(out_co[-1])\n",
    "        est_main = self.main_estimator(out_main[-1])\n",
    "\n",
    "#         import pdb; pdb.set_trace()   \n",
    "        return est_main,est_co, out_co,out_main\n",
    "\n",
    "    def reset(self):\n",
    "        self.co_rnn.reset()\n",
    "        self.main_rnn.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai2.learner.Learner at 0x7fa3adb80c18>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DualRNN(1,2,1,init_sz=500,linear_layer=2,rnn_layer=1,hidden_size=100,main_init_est=False,main_init_prop=False,residual=True)\n",
    "lrn = Learner(db,model,loss_func=nn.MSELoss(),cbs=ProDiagTrainer(),opt_func=ranger)\n",
    "lrn.add_cb(TbpttResetCB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DualCRNN(nn.Module):\n",
    "    \n",
    "    @delegates(RNN, keep=True)\n",
    "    def __init__(self,main_input_size,co_input_size,output_size,init_sz=100,tcn_hidden_size=100,tcn_layer=8,rnn_hidden_size=100,\n",
    "                 rnn_layer=1,linear_layer = 1,main_init_est = True,main_init_prop = True,**kwargs):\n",
    "        super().__init__()\n",
    "        store_attr(self,'main_input_size,co_input_size,main_init_est,main_init_prop,init_sz')\n",
    "        \n",
    "        rnn_kwargs = dict(hidden_size=rnn_hidden_size,num_layers=rnn_layer,stateful=True,ret_full_hidden=True)\n",
    "        rnn_kwargs = dict(rnn_kwargs, **kwargs)\n",
    "        \n",
    "        self.co_tcn = TCN(co_input_size,rnn_hidden_size,tcn_layer,tcn_hidden_size,stateful=True) \n",
    "        self.main_tcn = TCN(main_input_size,rnn_hidden_size,tcn_layer,tcn_hidden_size,stateful=True)\n",
    "        \n",
    "        self.co_rnn = RNN(rnn_hidden_size,**rnn_kwargs) \n",
    "        self.main_rnn = RNN(rnn_hidden_size,**rnn_kwargs) \n",
    "\n",
    "#         self.co_estimator = SeqLinear(rnn_hidden_size,output_size,hidden_layer=linear_layer)\n",
    "        self.main_estimator = SeqLinear(rnn_hidden_size,output_size,hidden_layer=linear_layer)\n",
    "\n",
    "    def forward(self, x,init_state = None):\n",
    "        if init_state is None:\n",
    "            init_state = self.main_rnn.hidden if self.main_init_prop else self.co_rnn.hidden\n",
    "        \n",
    "        \n",
    "        x_co = x[...,:self.co_input_size]\n",
    "        x_main = x[...,:self.main_input_size]\n",
    "        \n",
    "        #TCN Layer\n",
    "        x_co = self.co_tcn(x_co)\n",
    "        x_main = self.main_tcn(x_main)\n",
    "        \n",
    "            \n",
    "        #RNN Layer \n",
    "        if init_state is None:\n",
    "#             import pdb; pdb.set_trace()\n",
    "            if self.main_init_est:\n",
    "                out_init,h_init = self.main_rnn(x_main[:,:self.init_sz])\n",
    "                out_main,_ = self.main_rnn(x_main[:,self.init_sz:],h_init)\n",
    "                out_co,_ = self.co_rnn(x_co[:,self.init_sz:],h_init)  \n",
    "                out_main=torch.cat([out_init,out_main],2) \n",
    "                out_co=torch.cat([out_init,out_co],2) \n",
    "            else:\n",
    "                out_init,h_init = self.co_rnn(x_co[:,:self.init_sz])\n",
    "                out_co,_ = self.co_rnn(x_co[:,self.init_sz:],h_init)\n",
    "                out_main,_ = self.main_rnn(x_main[:,self.init_sz:],h_init)  \n",
    "                out_main=torch.cat([out_init,out_main],2) \n",
    "                out_co=torch.cat([out_init,out_co],2) \n",
    "        else:  \n",
    "            out_co,_ = self.co_rnn(x_co,init_state)         \n",
    "            out_main,_ = self.main_rnn(x_main,init_state)\n",
    "            \n",
    "            \n",
    "#         import pdb; pdb.set_trace()\n",
    "            \n",
    "        #Shared Linear Layer\n",
    "        est_co = self.main_estimator(out_co[-1])\n",
    "        est_main = self.main_estimator(out_main[-1])\n",
    "\n",
    "#         import pdb; pdb.set_trace()   \n",
    "        return est_main,est_co, out_co,out_main\n",
    "\n",
    "    def get_main_crnn(self):\n",
    "        crnn_model = CRNN(1,1)\n",
    "        crnn_model.cnn = self.main_tcn\n",
    "        \n",
    "        simple_rnn_model = SimpleRNN(1,1)\n",
    "        simple_rnn_model.rnn = self.main_rnn\n",
    "        simple_rnn_model.final = self.main_estimator\n",
    "        crnn_model.rnn = simple_rnn_model\n",
    "        return crnn_model\n",
    "    \n",
    "    \n",
    "    def get_co_crnn(self):\n",
    "        crnn_model = CRNN(1,1)\n",
    "        crnn_model.cnn = self.co_tcn\n",
    "        \n",
    "        simple_rnn_model = SimpleRNN(1,1)\n",
    "        simple_rnn_model.rnn = self.co_rnn\n",
    "        simple_rnn_model.final = self.main_estimator\n",
    "        crnn_model.rnn = simple_rnn_model\n",
    "        return crnn_model\n",
    "        \n",
    "\n",
    "    def reset(self):\n",
    "        self.co_rnn.reset()\n",
    "        self.main_rnn.reset()\n",
    "        self.co_tcn.reset()\n",
    "        self.main_tcn.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai2.learner.Learner at 0x7fa3ad7c74e0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DualCRNN(1,2,1,init_sz=500,main_init_est=False,main_init_prop=False,residual=True)\n",
    "lrn = Learner(db,model,loss_func=nn.MSELoss(),cbs=ProDiagTrainer(),opt_func=ranger)\n",
    "lrn.add_cb(TbpttResetCB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (cnn): TCN(\n",
       "    (conv1): Sequential(\n",
       "      (0): CausalConv1d(1, 100, kernel_size=(2,), stride=(1,), padding=(1,))\n",
       "      (1): Mish()\n",
       "    )\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): CausalConv1d(100, 100, kernel_size=(2,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (1): Mish()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): CausalConv1d(100, 100, kernel_size=(2,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (1): Mish()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): CausalConv1d(100, 100, kernel_size=(2,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (1): Mish()\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): CausalConv1d(100, 100, kernel_size=(2,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (1): Mish()\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): CausalConv1d(100, 100, kernel_size=(2,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (1): Mish()\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): CausalConv1d(100, 100, kernel_size=(2,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (1): Mish()\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): CausalConv1d(100, 100, kernel_size=(2,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "    )\n",
       "    (final): Conv1d(100, 100, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (rnn): SimpleRNN(\n",
       "    (rnn): RNN(\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): GRU(100, 100, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "      )\n",
       "      (norm_layers): ModuleList(\n",
       "        (0): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (final): SeqLinear(\n",
       "      (lin): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv1d(100, 100, kernel_size=(1,), stride=(1,))\n",
       "          (1): Mish()\n",
       "        )\n",
       "        (1): Conv1d(100, 1, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_main_crnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# btch = 6\n",
    "# plt.figure()\n",
    "# plt.plot(lrn.y.cpu()[btch,:,0])\n",
    "# plt.plot(lrn.pred.cpu()[btch,:,0])\n",
    "# plt.figure()\n",
    "# plt.plot(lrn.y.cpu()[btch,:,0])\n",
    "# plt.plot(lrn.pred.cpu()[btch,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_model.ipynb.\n",
      "Converted 02_learner.ipynb.\n",
      "Converted 03_dataloaders.ipynb.\n",
      "Converted 11_dualrnn.ipynb.\n",
      "Converted 12_TensorQuaternions.ipynb.\n",
      "Converted 13_HPOpt.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
